"""
–ü—Ä–æ–µ–∫—Ç —Å–µ–≥–º–µ–Ω—Ç–∞—Ü–∏–∏ –∫–ª–∏–µ–Ω—Ç–æ–≤ –±–∞–Ω–∫–∞ –Ω–∞ –æ—Å–Ω–æ–≤–µ –ø–æ–≤–µ–¥–µ–Ω—á–µ—Å–∫–∏—Ö —Ö–∞—Ä–∞–∫—Ç–µ—Ä–∏—Å—Ç–∏–∫
–ê–≤—Ç–æ—Ä: AI Assistant
–î–∞—Ç–∞: 2025
"""

import pandas as pd
import numpy as np
import matplotlib
matplotlib.use('Agg')  # –ò—Å–ø–æ–ª—å–∑—É–µ–º backend –±–µ–∑ GUI
import matplotlib.pyplot as plt
import seaborn as sns
import plotly.express as px
import plotly.graph_objects as go
from plotly.subplots import make_subplots
from sklearn.preprocessing import StandardScaler, RobustScaler
from sklearn.cluster import KMeans, DBSCAN
from sklearn.decomposition import PCA
from sklearn.metrics import silhouette_score, calinski_harabasz_score
from sklearn.ensemble import IsolationForest
import warnings
warnings.filterwarnings('ignore')

# –ë–µ–∑–æ–ø–∞—Å–Ω–∞—è –Ω–∞—Å—Ç—Ä–æ–π–∫–∞ —Å—Ç–∏–ª—è
plt.style.use('default')
try:
    sns.set_palette("husl")
except:
    pass

class BankClientSegmentation:
    """–ö–ª–∞—Å—Å –¥–ª—è —Å–µ–≥–º–µ–Ω—Ç–∞—Ü–∏–∏ –∫–ª–∏–µ–Ω—Ç–æ–≤ –±–∞–Ω–∫–∞"""
    
    def __init__(self, data_path):
        """–ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è —Å –∑–∞–≥—Ä—É–∑–∫–æ–π –¥–∞–Ω–Ω—ã—Ö"""
        print("üîÑ –ó–∞–≥—Ä—É–∂–∞–µ–º –¥–∞–Ω–Ω—ã–µ...")
        self.df = pd.read_parquet(data_path)
        print(f"‚úÖ –ó–∞–≥—Ä—É–∂–µ–Ω–æ {self.df.shape[0]:,} —Ç—Ä–∞–Ω–∑–∞–∫—Ü–∏–π")
        
        
        self.client_features = None
        self.scaled_features = None
        self.clusters = None
        self.scaler = None
        
    def explore_data(self):
        """–ü–µ—Ä–≤–∏—á–Ω—ã–π –∞–Ω–∞–ª–∏–∑ –¥–∞–Ω–Ω—ã—Ö"""
        print("\n" + "="*50)
        print("üìä –ê–ù–ê–õ–ò–ó –î–ê–ù–ù–´–•")
        print("="*50)
        
        print(f"–†–∞–∑–º–µ—Ä –¥–∞–Ω–Ω—ã—Ö: {self.df.shape}")
        print(f"–ü–µ—Ä–∏–æ–¥ –¥–∞–Ω–Ω—ã—Ö: {self.df['transaction_timestamp'].min()} - {self.df['transaction_timestamp'].max()}")
        print(f"–ö–æ–ª–∏—á–µ—Å—Ç–≤–æ —É–Ω–∏–∫–∞–ª—å–Ω—ã—Ö –∫–ª–∏–µ–Ω—Ç–æ–≤: {self.df['card_id'].nunique():,}")
        print(f"–ö–æ–ª–∏—á–µ—Å—Ç–≤–æ —É–Ω–∏–∫–∞–ª—å–Ω—ã—Ö –º–µ—Ä—á–∞–Ω—Ç–æ–≤: {self.df['merchant_id'].nunique():,}")
        
        
        missing_data = self.df.isnull().sum()
        if missing_data.sum() > 0:
            print("\nüîç –ü—Ä–æ–ø—É—â–µ–Ω–Ω—ã–µ –∑–Ω–∞—á–µ–Ω–∏—è:")
            print(missing_data[missing_data > 0])
        
        
        print(f"\nüí∞ –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ –ø–æ —Å—É–º–º–∞–º —Ç—Ä–∞–Ω–∑–∞–∫—Ü–∏–π:")
        print(f"–°—Ä–µ–¥–Ω—è—è —Å—É–º–º–∞: {self.df['transaction_amount_kzt'].mean():.2f} —Ç–µ–Ω–≥–µ")
        print(f"–ú–µ–¥–∏–∞–Ω–Ω–∞—è —Å—É–º–º–∞: {self.df['transaction_amount_kzt'].median():.2f} —Ç–µ–Ω–≥–µ")
        print(f"–û–±—â–∏–π –æ–±–æ—Ä–æ—Ç: {self.df['transaction_amount_kzt'].sum():,.2f} —Ç–µ–Ω–≥–µ")
        
    def create_client_features(self):
        """–°–æ–∑–¥–∞–Ω–∏–µ –ø–æ–≤–µ–¥–µ–Ω—á–µ—Å–∫–∏—Ö —Ö–∞—Ä–∞–∫—Ç–µ—Ä–∏—Å—Ç–∏–∫ –∫–ª–∏–µ–Ω—Ç–æ–≤"""
        print("\nüîß –°–æ–∑–¥–∞–µ–º –ø–æ–≤–µ–¥–µ–Ω—á–µ—Å–∫–∏–µ —Ö–∞—Ä–∞–∫—Ç–µ—Ä–∏—Å—Ç–∏–∫–∏ –∫–ª–∏–µ–Ω—Ç–æ–≤...")
        
        
        self.df['hour'] = self.df['transaction_timestamp'].dt.hour
        self.df['day_of_week'] = self.df['transaction_timestamp'].dt.dayofweek
        self.df['month'] = self.df['transaction_timestamp'].dt.month
        
        
        client_agg = self.df.groupby('card_id').agg({
            
            'transaction_id': 'count',  
            'transaction_amount_kzt': ['sum', 'mean', 'median', 'std', 'min', 'max'],
            
            
            'hour': lambda x: x.mode().iloc[0] if not x.mode().empty else 12,  
            'day_of_week': lambda x: x.mode().iloc[0] if not x.mode().empty else 0,  
            
            
            'merchant_id': 'nunique',  
            'mcc_category': 'nunique',  
            'merchant_city': 'nunique',  
            'transaction_type': lambda x: (x == 'Purchase').sum(),  
            
            
            'pos_entry_mode': lambda x: x.mode().iloc[0] if not x.mode().empty else 'Unknown',
            'wallet_type': lambda x: x.mode().iloc[0] if not x.mode().empty else 'Unknown'
        }).round(2)
        
        
        client_agg.columns = [
            'total_transactions', 'total_amount', 'avg_amount', 'median_amount', 
            'std_amount', 'min_amount', 'max_amount', 'preferred_hour', 
            'preferred_day', 'unique_merchants', 'unique_categories', 
            'unique_cities', 'purchase_count', 'preferred_pos_mode', 'preferred_wallet'
        ]
        
        
        client_agg['amount_range'] = client_agg['max_amount'] - client_agg['min_amount']
        client_agg['purchase_ratio'] = client_agg['purchase_count'] / client_agg['total_transactions']
        client_agg['avg_merchants_per_transaction'] = client_agg['unique_merchants'] / client_agg['total_transactions']
        client_agg['spending_consistency'] = 1 / (1 + client_agg['std_amount'] / client_agg['avg_amount'])
        
        
        client_agg['activity_level'] = pd.cut(
            client_agg['total_transactions'], 
            bins=[0, 10, 50, 200, float('inf')], 
            labels=['–ù–∏–∑–∫–∞—è', '–°—Ä–µ–¥–Ω—è—è', '–í—ã—Å–æ–∫–∞—è', '–û—á–µ–Ω—å –≤—ã—Å–æ–∫–∞—è']
        )
        
        
        client_agg['spending_level'] = pd.cut(
            client_agg['total_amount'], 
            bins=[0, 100000, 500000, 2000000, float('inf')], 
            labels=['–ù–∏–∑–∫–∏–π', '–°—Ä–µ–¥–Ω–∏–π', '–í—ã—Å–æ–∫–∏–π', '–ü—Ä–µ–º–∏—É–º']
        )
        
        self.client_features = client_agg
        print(f"‚úÖ –°–æ–∑–¥–∞–Ω–æ {len(self.client_features)} –ø—Ä–æ—Ñ–∏–ª–µ–π –∫–ª–∏–µ–Ω—Ç–æ–≤")
        
        return client_agg
    
    def prepare_features_for_clustering(self):
        """–ü–æ–¥–≥–æ—Ç–æ–≤–∫–∞ –ø—Ä–∏–∑–Ω–∞–∫–æ–≤ –¥–ª—è –∫–ª–∞—Å—Ç–µ—Ä–∏–∑–∞—Ü–∏–∏"""
        print("\nüéØ –ü–æ–¥–≥–æ—Ç–∞–≤–ª–∏–≤–∞–µ–º –ø—Ä–∏–∑–Ω–∞–∫–∏ –¥–ª—è –∫–ª–∞—Å—Ç–µ—Ä–∏–∑–∞—Ü–∏–∏...")
        
        
        numeric_features = [
            'total_transactions', 'total_amount', 'avg_amount', 'median_amount',
            'std_amount', 'amount_range', 'unique_merchants', 'unique_categories',
            'unique_cities', 'purchase_ratio', 'avg_merchants_per_transaction',
            'spending_consistency', 'preferred_hour', 'preferred_day'
        ]
        
        
        features_df = self.client_features[numeric_features].fillna(0)
        
        
        isolation_forest = IsolationForest(contamination=0.05, random_state=42)
        outlier_mask = isolation_forest.fit_predict(features_df) == 1
        
        print(f"üîç –û–±–Ω–∞—Ä—É–∂–µ–Ω–æ {(~outlier_mask).sum()} –≤—ã–±—Ä–æ—Å–æ–≤ ({(~outlier_mask).mean()*100:.1f}%)")
        
        
        features_clean = features_df[outlier_mask]
        
        
        self.scaler = RobustScaler()
        self.scaled_features = self.scaler.fit_transform(features_clean)
        
        print(f"‚úÖ –ü–æ–¥–≥–æ—Ç–æ–≤–ª–µ–Ω–æ {self.scaled_features.shape[0]} –∫–ª–∏–µ–Ω—Ç–æ–≤ –¥–ª—è –∫–ª–∞—Å—Ç–µ—Ä–∏–∑–∞—Ü–∏–∏")
        
        return self.scaled_features, features_clean.index
    
    def find_optimal_clusters(self, max_clusters=15):
        """–ü–æ–∏—Å–∫ –æ–ø—Ç–∏–º–∞–ª—å–Ω–æ–≥–æ –∫–æ–ª–∏—á–µ—Å—Ç–≤–∞ –∫–ª–∞—Å—Ç–µ—Ä–æ–≤"""
        print("\nüîç –ü–æ–∏—Å–∫ –æ–ø—Ç–∏–º–∞–ª—å–Ω–æ–≥–æ –∫–æ–ª–∏—á–µ—Å—Ç–≤–∞ –∫–ª–∞—Å—Ç–µ—Ä–æ–≤...")
        
        inertias = []
        silhouette_scores = []
        calinski_scores = []
        
        K_range = range(2, max_clusters + 1)
        
        for k in K_range:
            kmeans = KMeans(n_clusters=k, random_state=42, n_init=10)
            cluster_labels = kmeans.fit_predict(self.scaled_features)
            
            inertias.append(kmeans.inertia_)
            silhouette_scores.append(silhouette_score(self.scaled_features, cluster_labels))
            calinski_scores.append(calinski_harabasz_score(self.scaled_features, cluster_labels))
        
        
        fig, axes = plt.subplots(1, 3, figsize=(18, 5))
        
        
        axes[0].plot(K_range, inertias, 'bo-')
        axes[0].set_title('–ú–µ—Ç–æ–¥ –ª–æ–∫—Ç—è')
        axes[0].set_xlabel('–ö–æ–ª–∏—á–µ—Å—Ç–≤–æ –∫–ª–∞—Å—Ç–µ—Ä–æ–≤')
        axes[0].set_ylabel('–ò–Ω–µ—Ä—Ü–∏—è')
        axes[0].grid(True)
        
        
        axes[1].plot(K_range, silhouette_scores, 'ro-')
        axes[1].set_title('–°–∏–ª—É—ç—Ç–Ω—ã–π –∞–Ω–∞–ª–∏–∑')
        axes[1].set_xlabel('–ö–æ–ª–∏—á–µ—Å—Ç–≤–æ –∫–ª–∞—Å—Ç–µ—Ä–æ–≤')
        axes[1].set_ylabel('–°–∏–ª—É—ç—Ç–Ω—ã–π –∫–æ—ç—Ñ—Ñ–∏—Ü–∏–µ–Ω—Ç')
        axes[1].grid(True)
        
        
        axes[2].plot(K_range, calinski_scores, 'go-')
        axes[2].set_title('–ò–Ω–¥–µ–∫—Å –ö–∞–ª–∏–Ω—Å–∫–∏-–•–∞—Ä–∞–±–∞—à–∞')
        axes[2].set_xlabel('–ö–æ–ª–∏—á–µ—Å—Ç–≤–æ –∫–ª–∞—Å—Ç–µ—Ä–æ–≤')
        axes[2].set_ylabel('–ò–Ω–¥–µ–∫—Å CH')
        axes[2].grid(True)
        
        plt.tight_layout()
        plt.savefig('cluster_optimization.png', dpi=300, bbox_inches='tight')
        plt.close()  # –û—Å–≤–æ–±–æ–∂–¥–∞–µ–º –ø–∞–º—è—Ç—å
        print("‚úÖ –ì—Ä–∞—Ñ–∏–∫ –æ–ø—Ç–∏–º–∏–∑–∞—Ü–∏–∏ –∫–ª–∞—Å—Ç–µ—Ä–æ–≤ —Å–æ—Ö—Ä–∞–Ω–µ–Ω")
        
        
        optimal_k = K_range[np.argmax(silhouette_scores)]
        print(f"üéØ –†–µ–∫–æ–º–µ–Ω–¥—É–µ–º–æ–µ –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ –∫–ª–∞—Å—Ç–µ—Ä–æ–≤: {optimal_k}")
        
        return optimal_k
    
    def perform_clustering(self, n_clusters=None):
        """–í—ã–ø–æ–ª–Ω–µ–Ω–∏–µ –∫–ª–∞—Å—Ç–µ—Ä–∏–∑–∞—Ü–∏–∏"""
        if n_clusters is None:
            n_clusters = self.find_optimal_clusters()
        
        print(f"\nüéØ –í—ã–ø–æ–ª–Ω—è–µ–º –∫–ª–∞—Å—Ç–µ—Ä–∏–∑–∞—Ü–∏—é —Å {n_clusters} –∫–ª–∞—Å—Ç–µ—Ä–∞–º–∏...")
        
        
        kmeans = KMeans(n_clusters=n_clusters, random_state=42, n_init=10)
        cluster_labels = kmeans.fit_predict(self.scaled_features)
        
        
        silhouette_avg = silhouette_score(self.scaled_features, cluster_labels)
        calinski_score = calinski_harabasz_score(self.scaled_features, cluster_labels)
        
        print(f"üìä –ö–∞—á–µ—Å—Ç–≤–æ –∫–ª–∞—Å—Ç–µ—Ä–∏–∑–∞—Ü–∏–∏:")
        print(f"   –°–∏–ª—É—ç—Ç–Ω—ã–π –∫–æ—ç—Ñ—Ñ–∏—Ü–∏–µ–Ω—Ç: {silhouette_avg:.3f}")
        print(f"   –ò–Ω–¥–µ–∫—Å –ö–∞–ª–∏–Ω—Å–∫–∏-–•–∞—Ä–∞–±–∞—à–∞: {calinski_score:.2f}")
        
        self.clusters = cluster_labels
        self.kmeans_model = kmeans
        
        return cluster_labels
    
    def analyze_clusters(self):
        """–ê–Ω–∞–ª–∏–∑ –ø–æ–ª—É—á–µ–Ω–Ω—ã—Ö –∫–ª–∞—Å—Ç–µ—Ä–æ–≤"""
        print("\nüìà –ê–ù–ê–õ–ò–ó –ö–õ–ê–°–¢–ï–†–û–í")
        print("="*50)
        
        
        valid_indices = self.client_features.index[self.client_features.index.isin(
            self.client_features.index[~self.client_features.index.duplicated()]
        )]
        
        
        cluster_df = self.client_features.loc[valid_indices[:len(self.clusters)]].copy()
        cluster_df['cluster'] = self.clusters
        
        
        cluster_sizes = cluster_df['cluster'].value_counts().sort_index()
        print("–†–∞–∑–º–µ—Ä—ã –∫–ª–∞—Å—Ç–µ—Ä–æ–≤:")
        for cluster_id, size in cluster_sizes.items():
            percentage = (size / len(cluster_df)) * 100
            print(f"  –ö–ª–∞—Å—Ç–µ—Ä {cluster_id}: {size:,} –∫–ª–∏–µ–Ω—Ç–æ–≤ ({percentage:.1f}%)")
        
        
        print("\nüìä –•–∞—Ä–∞–∫—Ç–µ—Ä–∏—Å—Ç–∏–∫–∏ –∫–ª–∞—Å—Ç–µ—Ä–æ–≤:")
        
        key_metrics = ['total_transactions', 'total_amount', 'avg_amount', 
                      'unique_merchants', 'unique_categories', 'purchase_ratio']
        
        cluster_summary = cluster_df.groupby('cluster')[key_metrics].agg(['mean', 'median']).round(2)
        
        for cluster_id in sorted(cluster_df['cluster'].unique()):
            print(f"\nüéØ –ö–õ–ê–°–¢–ï–† {cluster_id}:")
            cluster_data = cluster_df[cluster_df['cluster'] == cluster_id]
            
            print(f"   –†–∞–∑–º–µ—Ä: {len(cluster_data):,} –∫–ª–∏–µ–Ω—Ç–æ–≤")
            print(f"   –°—Ä–µ–¥–Ω–µ–µ –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ —Ç—Ä–∞–Ω–∑–∞–∫—Ü–∏–π: {cluster_data['total_transactions'].mean():.1f}")
            print(f"   –°—Ä–µ–¥–Ω—è—è –æ–±—â–∞—è —Å—É–º–º–∞: {cluster_data['total_amount'].mean():,.0f} —Ç–µ–Ω–≥–µ")
            print(f"   –°—Ä–µ–¥–Ω–∏–π —á–µ–∫: {cluster_data['avg_amount'].mean():,.0f} —Ç–µ–Ω–≥–µ")
            print(f"   –°—Ä–µ–¥–Ω–µ–µ –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ –º–µ—Ä—á–∞–Ω—Ç–æ–≤: {cluster_data['unique_merchants'].mean():.1f}")
            print(f"   –î–æ–ª—è –ø–æ–∫—É–ø–æ–∫: {cluster_data['purchase_ratio'].mean():.2f}")
            
            
            if cluster_data['total_transactions'].mean() > cluster_df['total_transactions'].mean():
                if cluster_data['avg_amount'].mean() > cluster_df['avg_amount'].mean():
                    cluster_type = "üåü –ü—Ä–µ–º–∏—É–º –∫–ª–∏–µ–Ω—Ç—ã (–≤—ã—Å–æ–∫–∞—è –∞–∫—Ç–∏–≤–Ω–æ—Å—Ç—å + –≤—ã—Å–æ–∫–∏–π —á–µ–∫)"
                else:
                    cluster_type = "‚ö° –ê–∫—Ç–∏–≤–Ω—ã–µ –∫–ª–∏–µ–Ω—Ç—ã (–≤—ã—Å–æ–∫–∞—è –∞–∫—Ç–∏–≤–Ω–æ—Å—Ç—å + —Å—Ä–µ–¥–Ω–∏–π —á–µ–∫)"
            else:
                if cluster_data['avg_amount'].mean() > cluster_df['avg_amount'].mean():
                    cluster_type = "üíé VIP –∫–ª–∏–µ–Ω—Ç—ã (–Ω–∏–∑–∫–∞—è –∞–∫—Ç–∏–≤–Ω–æ—Å—Ç—å + –≤—ã—Å–æ–∫–∏–π —á–µ–∫)"
                else:
                    cluster_type = "üò¥ –ü–∞—Å—Å–∏–≤–Ω—ã–µ –∫–ª–∏–µ–Ω—Ç—ã (–Ω–∏–∑–∫–∞—è –∞–∫—Ç–∏–≤–Ω–æ—Å—Ç—å + –Ω–∏–∑–∫–∏–π —á–µ–∫)"
            
            print(f"   –¢–∏–ø: {cluster_type}")
        
        return cluster_df
    
    def visualize_clusters(self, cluster_df):
        """–í–∏–∑—É–∞–ª–∏–∑–∞—Ü–∏—è –∫–ª–∞—Å—Ç–µ—Ä–æ–≤"""
        print("\nüé® –°–æ–∑–¥–∞–µ–º –≤–∏–∑—É–∞–ª–∏–∑–∞—Ü–∏–∏...")
        
        
        pca = PCA(n_components=2, random_state=42)
        pca_features = pca.fit_transform(self.scaled_features)
        
        
        fig = make_subplots(
            rows=2, cols=2,
            subplot_titles=('–ö–ª–∞—Å—Ç–µ—Ä—ã –≤ –ø—Ä–æ—Å—Ç—Ä–∞–Ω—Å—Ç–≤–µ PCA', '–†–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ –ø–æ –∞–∫—Ç–∏–≤–Ω–æ—Å—Ç–∏',
                          '–†–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ –ø–æ —Å—É–º–º–∞–º', '–°–æ–æ—Ç–Ω–æ—à–µ–Ω–∏–µ –∞–∫—Ç–∏–≤–Ω–æ—Å—Ç–∏ –∏ —Å—É–º–º'),
            specs=[[{"type": "scatter"}, {"type": "bar"}],
                   [{"type": "bar"}, {"type": "scatter"}]]
        )
        
        
        colors = px.colors.qualitative.Set1[:len(cluster_df['cluster'].unique())]
        for i, cluster_id in enumerate(sorted(cluster_df['cluster'].unique())):
            mask = self.clusters == cluster_id
            fig.add_trace(
                go.Scatter(
                    x=pca_features[mask, 0],
                    y=pca_features[mask, 1],
                    mode='markers',
                    name=f'–ö–ª–∞—Å—Ç–µ—Ä {cluster_id}',
                    marker=dict(color=colors[i], size=5, opacity=0.6),
                    showlegend=True
                ),
                row=1, col=1
            )
        
        
        cluster_transactions = cluster_df.groupby('cluster')['total_transactions'].mean()
        fig.add_trace(
            go.Bar(
                x=[f'–ö–ª–∞—Å—Ç–µ—Ä {i}' for i in cluster_transactions.index],
                y=cluster_transactions.values,
                name='–°—Ä–µ–¥–Ω–µ–µ –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ —Ç—Ä–∞–Ω–∑–∞–∫—Ü–∏–π',
                marker_color=colors[:len(cluster_transactions)],
                showlegend=False
            ),
            row=1, col=2
        )
        
        
        cluster_amounts = cluster_df.groupby('cluster')['total_amount'].mean()
        fig.add_trace(
            go.Bar(
                x=[f'–ö–ª–∞—Å—Ç–µ—Ä {i}' for i in cluster_amounts.index],
                y=cluster_amounts.values,
                name='–°—Ä–µ–¥–Ω—è—è –æ–±—â–∞—è —Å—É–º–º–∞',
                marker_color=colors[:len(cluster_amounts)],
                showlegend=False
            ),
            row=2, col=1
        )
        
        
        cluster_avg_amounts = cluster_df.groupby('cluster')['avg_amount'].mean()
        fig.add_trace(
            go.Scatter(
                x=cluster_transactions.values,
                y=cluster_avg_amounts.values,
                mode='markers+text',
                text=[f'–ö–ª–∞—Å—Ç–µ—Ä {i}' for i in cluster_transactions.index],
                textposition="top center",
                marker=dict(
                    size=cluster_df.groupby('cluster').size().values / 10,
                    color=colors[:len(cluster_transactions)],
                    opacity=0.7
                ),
                name='–ö–ª–∞—Å—Ç–µ—Ä—ã',
                showlegend=False
            ),
            row=2, col=2
        )
        
        
        fig.update_layout(
            title_text="–ê–Ω–∞–ª–∏–∑ –∫–ª–∞—Å—Ç–µ—Ä–æ–≤ –∫–ª–∏–µ–Ω—Ç–æ–≤ –±–∞–Ω–∫–∞",
            title_x=0.5,
            height=800,
            showlegend=True
        )
        
        
        fig.update_xaxes(title_text="PC1", row=1, col=1)
        fig.update_yaxes(title_text="PC2", row=1, col=1)
        fig.update_yaxes(title_text="–ö–æ–ª–∏—á–µ—Å—Ç–≤–æ —Ç—Ä–∞–Ω–∑–∞–∫—Ü–∏–π", row=1, col=2)
        fig.update_yaxes(title_text="–û–±—â–∞—è —Å—É–º–º–∞ (—Ç–µ–Ω–≥–µ)", row=2, col=1)
        fig.update_xaxes(title_text="–ö–æ–ª–∏—á–µ—Å—Ç–≤–æ —Ç—Ä–∞–Ω–∑–∞–∫—Ü–∏–π", row=2, col=2)
        fig.update_yaxes(title_text="–°—Ä–µ–¥–Ω–∏–π —á–µ–∫ (—Ç–µ–Ω–≥–µ)", row=2, col=2)
        
        fig.write_html("cluster_analysis.html")
        print("‚úÖ –ò–Ω—Ç–µ—Ä–∞–∫—Ç–∏–≤–Ω–∞—è –≤–∏–∑—É–∞–ª–∏–∑–∞—Ü–∏—è —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∞ –≤ cluster_analysis.html")
        
        
        plt.figure(figsize=(15, 10))
        
        
        plt.subplot(2, 3, 1)
        scatter = plt.scatter(pca_features[:, 0], pca_features[:, 1], 
                            c=self.clusters, cmap='tab10', alpha=0.6)
        plt.title('–ö–ª–∞—Å—Ç–µ—Ä—ã –≤ –ø—Ä–æ—Å—Ç—Ä–∞–Ω—Å—Ç–≤–µ PCA')
        plt.xlabel(f'PC1 ({pca.explained_variance_ratio_[0]:.1%} –¥–∏—Å–ø–µ—Ä—Å–∏–∏)')
        plt.ylabel(f'PC2 ({pca.explained_variance_ratio_[1]:.1%} –¥–∏—Å–ø–µ—Ä—Å–∏–∏)')
        plt.colorbar(scatter)
        
        
        plt.subplot(2, 3, 2)
        cluster_sizes = cluster_df['cluster'].value_counts().sort_index()
        plt.bar(range(len(cluster_sizes)), cluster_sizes.values)
        plt.title('–†–∞–∑–º–µ—Ä—ã –∫–ª–∞—Å—Ç–µ—Ä–æ–≤')
        plt.xlabel('–ö–ª–∞—Å—Ç–µ—Ä')
        plt.ylabel('–ö–æ–ª–∏—á–µ—Å—Ç–≤–æ –∫–ª–∏–µ–Ω—Ç–æ–≤')
        plt.xticks(range(len(cluster_sizes)), [f'–ö–ª–∞—Å—Ç–µ—Ä {i}' for i in cluster_sizes.index])
        
        
        plt.subplot(2, 3, 3)
        cluster_transactions = cluster_df.groupby('cluster')['total_transactions'].mean()
        plt.bar(range(len(cluster_transactions)), cluster_transactions.values)
        plt.title('–°—Ä–µ–¥–Ω–µ–µ –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ —Ç—Ä–∞–Ω–∑–∞–∫—Ü–∏–π')
        plt.xlabel('–ö–ª–∞—Å—Ç–µ—Ä')
        plt.ylabel('–ö–æ–ª–∏—á–µ—Å—Ç–≤–æ —Ç—Ä–∞–Ω–∑–∞–∫—Ü–∏–π')
        plt.xticks(range(len(cluster_transactions)), [f'–ö–ª–∞—Å—Ç–µ—Ä {i}' for i in cluster_transactions.index])
        
        
        plt.subplot(2, 3, 4)
        cluster_amounts = cluster_df.groupby('cluster')['total_amount'].mean()
        plt.bar(range(len(cluster_amounts)), cluster_amounts.values)
        plt.title('–°—Ä–µ–¥–Ω—è—è –æ–±—â–∞—è —Å—É–º–º–∞')
        plt.xlabel('–ö–ª–∞—Å—Ç–µ—Ä')
        plt.ylabel('–°—É–º–º–∞ (—Ç–µ–Ω–≥–µ)')
        plt.xticks(range(len(cluster_amounts)), [f'–ö–ª–∞—Å—Ç–µ—Ä {i}' for i in cluster_amounts.index])
        
        
        plt.subplot(2, 3, 5)
        cluster_avg_amounts = cluster_df.groupby('cluster')['avg_amount'].mean()
        plt.bar(range(len(cluster_avg_amounts)), cluster_avg_amounts.values)
        plt.title('–°—Ä–µ–¥–Ω–∏–π —á–µ–∫')
        plt.xlabel('–ö–ª–∞—Å—Ç–µ—Ä')
        plt.ylabel('–°—Ä–µ–¥–Ω–∏–π —á–µ–∫ (—Ç–µ–Ω–≥–µ)')
        plt.xticks(range(len(cluster_avg_amounts)), [f'–ö–ª–∞—Å—Ç–µ—Ä {i}' for i in cluster_avg_amounts.index])
        
        
        plt.subplot(2, 3, 6)
        key_metrics = ['total_transactions', 'total_amount', 'avg_amount', 'unique_merchants']
        cluster_heatmap_data = cluster_df.groupby('cluster')[key_metrics].mean()
        
        # –ù–æ—Ä–º–∞–ª–∏–∑–∞—Ü–∏—è –¥–∞–Ω–Ω—ã—Ö –¥–ª—è —Ç–µ–ø–ª–æ–≤–æ–π –∫–∞—Ä—Ç—ã
        try:
            cluster_heatmap_normalized = (cluster_heatmap_data - cluster_heatmap_data.min()) / (cluster_heatmap_data.max() - cluster_heatmap_data.min())
            
            # –ó–∞–º–µ–Ω—è–µ–º NaN –Ω–∞ 0 –µ—Å–ª–∏ –µ—Å—Ç—å
            cluster_heatmap_normalized = cluster_heatmap_normalized.fillna(0)
            
            sns.heatmap(cluster_heatmap_normalized.T, annot=True, cmap='YlOrRd', 
                       xticklabels=[f'–ö–ª–∞—Å—Ç–µ—Ä {i}' for i in cluster_heatmap_data.index],
                       yticklabels=['–¢—Ä–∞–Ω–∑–∞–∫—Ü–∏–∏', '–û–±—â–∞—è —Å—É–º–º–∞', '–°—Ä–µ–¥–Ω–∏–π —á–µ–∫', '–ú–µ—Ä—á–∞–Ω—Ç—ã'],
                       fmt='.2f')
            plt.title('–ù–æ—Ä–º–∞–ª–∏–∑–æ–≤–∞–Ω–Ω—ã–µ —Ö–∞—Ä–∞–∫—Ç–µ—Ä–∏—Å—Ç–∏–∫–∏ –∫–ª–∞—Å—Ç–µ—Ä–æ–≤')
        except Exception as e:
            print(f"‚ö†Ô∏è –û—à–∏–±–∫–∞ –ø—Ä–∏ —Å–æ–∑–¥–∞–Ω–∏–∏ —Ç–µ–ø–ª–æ–≤–æ–π –∫–∞—Ä—Ç—ã: {e}")
            plt.text(0.5, 0.5, '–û—à–∏–±–∫–∞ —Å–æ–∑–¥–∞–Ω–∏—è\n—Ç–µ–ø–ª–æ–≤–æ–π –∫–∞—Ä—Ç—ã', 
                    ha='center', va='center', transform=plt.gca().transAxes)
            plt.title('–•–∞—Ä–∞–∫—Ç–µ—Ä–∏—Å—Ç–∏–∫–∏ –∫–ª–∞—Å—Ç–µ—Ä–æ–≤ (–æ—à–∏–±–∫–∞)')
        
        plt.tight_layout()
        plt.savefig('cluster_static_analysis.png', dpi=300, bbox_inches='tight')
        plt.close()  # –û—Å–≤–æ–±–æ–∂–¥–∞–µ–º –ø–∞–º—è—Ç—å
        print("‚úÖ –°—Ç–∞—Ç–∏—á–µ—Å–∫–∏–µ –≥—Ä–∞—Ñ–∏–∫–∏ —Å–æ–∑–¥–∞–Ω—ã –∏ —Å–æ—Ö—Ä–∞–Ω–µ–Ω—ã")
    
    def generate_business_recommendations(self, cluster_df):
        """–ì–µ–Ω–µ—Ä–∞—Ü–∏—è –±–∏–∑–Ω–µ—Å-—Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–π"""
        print("\nüíº –ë–ò–ó–ù–ï–°-–†–ï–ö–û–ú–ï–ù–î–ê–¶–ò–ò")
        print("="*50)
        
        for cluster_id in sorted(cluster_df['cluster'].unique()):
            cluster_data = cluster_df[cluster_df['cluster'] == cluster_id]
            size_pct = (len(cluster_data) / len(cluster_df)) * 100
            
            print(f"\nüéØ –ö–õ–ê–°–¢–ï–† {cluster_id} ({size_pct:.1f}% –∫–ª–∏–µ–Ω—Ç–æ–≤):")
            
            avg_transactions = cluster_data['total_transactions'].mean()
            avg_amount = cluster_data['avg_amount'].mean()
            avg_total = cluster_data['total_amount'].mean()
            avg_merchants = cluster_data['unique_merchants'].mean()
            
            
            if avg_transactions > cluster_df['total_transactions'].mean():
                if avg_amount > cluster_df['avg_amount'].mean():
                    print("   üìà –¢–ò–ü: –ü—Ä–µ–º–∏—É–º –∫–ª–∏–µ–Ω—Ç—ã")
                    print("   üéØ –°–¢–†–ê–¢–ï–ì–ò–Ø:")
                    print("     ‚Ä¢ –ü—Ä–æ–≥—Ä–∞–º–º—ã –ª–æ—è–ª—å–Ω–æ—Å—Ç–∏ —Å —ç–∫—Å–∫–ª—é–∑–∏–≤–Ω—ã–º–∏ –ø—Ä–∏–≤–∏–ª–µ–≥–∏—è–º–∏")
                    print("     ‚Ä¢ –ü–µ—Ä—Å–æ–Ω–∞–ª—å–Ω—ã–π –º–µ–Ω–µ–¥–∂–µ—Ä")
                    print("     ‚Ä¢ –ü—Ä–µ–º–∏—É–º –ø—Ä–æ–¥—É–∫—Ç—ã (Private Banking)")
                    print("     ‚Ä¢ –ò–Ω–≤–µ—Å—Ç–∏—Ü–∏–æ–Ω–Ω—ã–µ –ø—Ä–æ–¥—É–∫—Ç—ã")
                    print("     ‚Ä¢ –ö—ç—à–±—ç–∫ –ø—Ä–æ–≥—Ä–∞–º–º—ã —Å –ø–æ–≤—ã—à–µ–Ω–Ω—ã–º–∏ —Å—Ç–∞–≤–∫–∞–º–∏")
                else:
                    print("   ‚ö° –¢–ò–ü: –ê–∫—Ç–∏–≤–Ω—ã–µ –∫–ª–∏–µ–Ω—Ç—ã")
                    print("   üéØ –°–¢–†–ê–¢–ï–ì–ò–Ø:")
                    print("     ‚Ä¢ –ü—Ä–æ–≥—Ä–∞–º–º—ã –ª–æ—è–ª—å–Ω–æ—Å—Ç–∏ —Å –±–æ–Ω—É—Å–∞–º–∏ –∑–∞ –∞–∫—Ç–∏–≤–Ω–æ—Å—Ç—å")
                    print("     ‚Ä¢ –ö—Ä–µ–¥–∏—Ç–Ω—ã–µ –ø—Ä–æ–¥—É–∫—Ç—ã —Å –ª—å–≥–æ—Ç–Ω—ã–º–∏ —É—Å–ª–æ–≤–∏—è–º–∏")
                    print("     ‚Ä¢ –ú–æ–±–∏–ª—å–Ω—ã–µ –ø—Ä–∏–ª–æ–∂–µ–Ω–∏—è —Å —Ä–∞—Å—à–∏—Ä–µ–Ω–Ω—ã–º —Ñ—É–Ω–∫—Ü–∏–æ–Ω–∞–ª–æ–º")
                    print("     ‚Ä¢ –ö—ç—à–±—ç–∫ –≤ –ø–æ–ø—É–ª—è—Ä–Ω—ã—Ö –∫–∞—Ç–µ–≥–æ—Ä–∏—è—Ö")
                    print("     ‚Ä¢ –£–≤–µ–¥–æ–º–ª–µ–Ω–∏—è –æ —Å–ø–µ—Ü–∏–∞–ª—å–Ω—ã—Ö –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏—è—Ö")
            else:
                if avg_amount > cluster_df['avg_amount'].mean():
                    print("   üíé –¢–ò–ü: VIP –∫–ª–∏–µ–Ω—Ç—ã")
                    print("   üéØ –°–¢–†–ê–¢–ï–ì–ò–Ø:")
                    print("     ‚Ä¢ –°—Ç–∏–º—É–ª–∏—Ä–æ–≤–∞–Ω–∏–µ —á–∞—Å—Ç–æ—Ç—ã –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—è –∫–∞—Ä—Ç")
                    print("     ‚Ä¢ –°–ø–µ—Ü–∏–∞–ª—å–Ω—ã–µ –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏—è –¥–ª—è —É–≤–µ–ª–∏—á–µ–Ω–∏—è –∞–∫—Ç–∏–≤–Ω–æ—Å—Ç–∏")
                    print("     ‚Ä¢ –ö–æ–Ω—Å—å–µ—Ä–∂-—Å–µ—Ä–≤–∏—Å—ã")
                    print("     ‚Ä¢ –≠–∫—Å–∫–ª—é–∑–∏–≤–Ω—ã–µ –º–µ—Ä–æ–ø—Ä–∏—è—Ç–∏—è")
                    print("     ‚Ä¢ –ü–µ—Ä—Å–æ–Ω–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω–Ω—ã–µ –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏—è")
                else:
                    print("   üò¥ –¢–ò–ü: –ü–∞—Å—Å–∏–≤–Ω—ã–µ –∫–ª–∏–µ–Ω—Ç—ã")
                    print("   üéØ –°–¢–†–ê–¢–ï–ì–ò–Ø:")
                    print("     ‚Ä¢ –†–µ–∞–∫—Ç–∏–≤–∞—Ü–∏–æ–Ω–Ω—ã–µ –∫–∞–º–ø–∞–Ω–∏–∏")
                    print("     ‚Ä¢ –û–±—Ä–∞–∑–æ–≤–∞—Ç–µ–ª—å–Ω—ã–µ –ø—Ä–æ–≥—Ä–∞–º–º—ã –ø–æ —Ñ–∏–Ω–∞–Ω—Å–æ–≤–æ–π –≥—Ä–∞–º–æ—Ç–Ω–æ—Å—Ç–∏")
                    print("     ‚Ä¢ –ü—Ä–æ—Å—Ç—ã–µ –∏ –ø–æ–Ω—è—Ç–Ω—ã–µ –ø—Ä–æ–¥—É–∫—Ç—ã")
                    print("     ‚Ä¢ –°—Ç–∏–º—É–ª–∏—Ä—É—é—â–∏–µ –∞–∫—Ü–∏–∏ –¥–ª—è –ø–µ—Ä–≤—ã—Ö —Ç—Ä–∞–Ω–∑–∞–∫—Ü–∏–π")
                    print("     ‚Ä¢ –£–ø—Ä–æ—â–µ–Ω–∏–µ –ø—Ä–æ—Ü–µ—Å—Å–æ–≤ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—è –∫–∞—Ä—Ç")
            
            print(f"   üìä –ö–õ–Æ–ß–ï–í–´–ï –ú–ï–¢–†–ò–ö–ò:")
            print(f"     ‚Ä¢ –°—Ä–µ–¥–Ω–µ–µ –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ —Ç—Ä–∞–Ω–∑–∞–∫—Ü–∏–π: {avg_transactions:.1f}")
            print(f"     ‚Ä¢ –°—Ä–µ–¥–Ω–∏–π —á–µ–∫: {avg_amount:,.0f} —Ç–µ–Ω–≥–µ")
            print(f"     ‚Ä¢ –°—Ä–µ–¥–Ω–∏–π –æ–±–æ—Ä–æ—Ç: {avg_total:,.0f} —Ç–µ–Ω–≥–µ")
            print(f"     ‚Ä¢ –°—Ä–µ–¥–Ω–µ–µ –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ –º–µ—Ä—á–∞–Ω—Ç–æ–≤: {avg_merchants:.1f}")
    
    def save_results(self, cluster_df):
        """–°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤"""
        print("\nüíæ –°–æ—Ö—Ä–∞–Ω—è–µ–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã...")
        
        
        cluster_df.to_csv('client_segments.csv', index=True)
        
        
        summary_stats = cluster_df.groupby('cluster').agg({
            'total_transactions': ['count', 'mean', 'median', 'std'],
            'total_amount': ['mean', 'median', 'std'],
            'avg_amount': ['mean', 'median', 'std'],
            'unique_merchants': ['mean', 'median'],
            'unique_categories': ['mean', 'median'],
            'purchase_ratio': ['mean', 'median']
        }).round(2)
        
        summary_stats.to_csv('cluster_summary_statistics.csv')
        
        print("‚úÖ –†–µ–∑—É–ª—å—Ç–∞—Ç—ã —Å–æ—Ö—Ä–∞–Ω–µ–Ω—ã:")
        print("   ‚Ä¢ client_segments.csv - –¥–µ—Ç–∞–ª—å–Ω–∞—è –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è –ø–æ –∫–ª–∏–µ–Ω—Ç–∞–º")
        print("   ‚Ä¢ cluster_summary_statistics.csv - —Å–≤–æ–¥–Ω–∞—è —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ –ø–æ –∫–ª–∞—Å—Ç–µ—Ä–∞–º")
        print("   ‚Ä¢ cluster_analysis.html - –∏–Ω—Ç–µ—Ä–∞–∫—Ç–∏–≤–Ω–∞—è –≤–∏–∑—É–∞–ª–∏–∑–∞—Ü–∏—è")
        print("   ‚Ä¢ cluster_static_analysis.png - —Å—Ç–∞—Ç–∏—á–Ω—ã–µ –≥—Ä–∞—Ñ–∏–∫–∏")
    
    def run_full_analysis(self, n_clusters=None):
        """–ó–∞–ø—É—Å–∫ –ø–æ–ª–Ω–æ–≥–æ –∞–Ω–∞–ª–∏–∑–∞"""
        print("üöÄ –ó–ê–ü–£–°–ö –ü–û–õ–ù–û–ì–û –ê–ù–ê–õ–ò–ó–ê –°–ï–ì–ú–ï–ù–¢–ê–¶–ò–ò –ö–õ–ò–ï–ù–¢–û–í")
        print("="*60)
        
        
        self.explore_data()
        
        
        self.create_client_features()
        
        
        self.prepare_features_for_clustering()
        
        
        self.perform_clustering(n_clusters)
        
        
        cluster_df = self.analyze_clusters()
        
        
        self.visualize_clusters(cluster_df)
        
        
        self.generate_business_recommendations(cluster_df)
        
        
        self.save_results(cluster_df)
        
        print("\nüéâ –ê–ù–ê–õ–ò–ó –ó–ê–í–ï–†–®–ï–ù!")
        print("="*60)
        
        return cluster_df


def main():
    """–û—Å–Ω–æ–≤–Ω–∞—è —Ñ—É–Ω–∫—Ü–∏—è"""
    
    segmentation = BankClientSegmentation('DECENTRATHON_3.0.parquet')
    
    
    results = segmentation.run_full_analysis()
    
    return segmentation, results

if __name__ == "__main__":
    segmentation, results = main() 