#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
–°–æ–∑–¥–∞–Ω–∏–µ —Ñ–∞–π–ª–∞ —Å —Ä–µ–∑—É–ª—å—Ç–∞—Ç–∞–º–∏ —Å–µ–≥–º–µ–Ω—Ç–∞—Ü–∏–∏ –≤ —Ñ–æ—Ä–º–∞—Ç–µ .parquet
–í–∫–ª—é—á–∞–µ—Ç –¥–∞–Ω–Ω—ã–µ –æ –∫–ª–∏–µ–Ω—Ç–∞—Ö, –∏—Ö —Å–µ–≥–º–µ–Ω—Ç–∞—Ö –∏ —Ö–∞—Ä–∞–∫—Ç–µ—Ä–∏—Å—Ç–∏–∫–∞—Ö
"""

import pandas as pd
import json
import os
from datetime import datetime

def create_segmentation_parquet():
    """–°–æ–∑–¥–∞–µ—Ç —Ñ–∞–π–ª —Å —Ä–µ–∑—É–ª—å—Ç–∞—Ç–∞–º–∏ —Å–µ–≥–º–µ–Ω—Ç–∞—Ü–∏–∏ –≤ —Ñ–æ—Ä–º–∞—Ç–µ .parquet"""
    
    print("üîÑ –°–æ–∑–¥–∞–Ω–∏–µ —Ñ–∞–π–ª–∞ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤ —Å–µ–≥–º–µ–Ω—Ç–∞—Ü–∏–∏ –≤ —Ñ–æ—Ä–º–∞—Ç–µ .parquet...")
    
    # –ó–∞–≥—Ä—É–∂–∞–µ–º –æ—Å–Ω–æ–≤–Ω—ã–µ –¥–∞–Ω–Ω—ã–µ —Å–µ–≥–º–µ–Ω—Ç–∞—Ü–∏–∏
    print("üìä –ó–∞–≥—Ä—É–∑–∫–∞ –¥–∞–Ω–Ω—ã—Ö —Å–µ–≥–º–µ–Ω—Ç–∞—Ü–∏–∏...")
    segments_df = pd.read_csv('results/client_segments.csv')
    
    # –ó–∞–≥—Ä—É–∂–∞–µ–º –ø—Ä–æ—Ñ–∏–ª–∏ —Å–µ–≥–º–µ–Ω—Ç–æ–≤ –¥–ª—è –¥–æ–±–∞–≤–ª–µ–Ω–∏—è –æ–ø–∏—Å–∞–Ω–∏–π
    print("üìã –ó–∞–≥—Ä—É–∑–∫–∞ –ø—Ä–æ—Ñ–∏–ª–µ–π —Å–µ–≥–º–µ–Ω—Ç–æ–≤...")
    with open('results/segment_profiles.json', 'r', encoding='utf-8') as f:
        segment_profiles = json.load(f)
    
    # –°–æ–∑–¥–∞–µ–º —Å–ª–æ–≤–∞—Ä—å –¥–ª—è –º–∞–ø–ø–∏–Ω–≥–∞ –∫–ª–∞—Å—Ç–µ—Ä–æ–≤ –∫ –Ω–∞–∑–≤–∞–Ω–∏—è–º —Å–µ–≥–º–µ–Ω—Ç–æ–≤
    cluster_to_segment = {}
    for segment_name, segment_data in segment_profiles.items():
        if '–û–±—ã—á–Ω—ã–µ' in segment_name:
            cluster_to_segment[0] = {
                'segment_name': '–û–±—ã—á–Ω—ã–µ –∫–ª–∏–µ–Ω—Ç—ã',
                'segment_emoji': 'üîÑ',
                'segment_description': '–ê–∫—Ç–∏–≤–Ω—ã–µ –∫–ª–∏–µ–Ω—Ç—ã —Å –≤—ã—Å–æ–∫–æ–π —Ü–∏—Ñ—Ä–æ–≤–æ–π –∞–∫—Ç–∏–≤–Ω–æ—Å—Ç—å—é',
                'business_strategy': '–†–∞–∑–≤–∏—Ç–∏–µ –∏ —É–¥–µ—Ä–∂–∞–Ω–∏–µ'
            }
        elif '–°–ø—è—â–∏–µ' in segment_name:
            cluster_to_segment[1] = {
                'segment_name': '–°–ø—è—â–∏–µ –∫–ª–∏–µ–Ω—Ç—ã', 
                'segment_emoji': 'üò¥',
                'segment_description': '–ö–ª–∏–µ–Ω—Ç—ã —Å –Ω–∏–∑–∫–æ–π –∞–∫—Ç–∏–≤–Ω–æ—Å—Ç—å—é –∏ –æ–≥—Ä–∞–Ω–∏—á–µ–Ω–Ω—ã–º –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ–º —É—Å–ª—É–≥',
                'business_strategy': '–†–µ–∞–∫—Ç–∏–≤–∞—Ü–∏—è –∏ –≤–æ–≤–ª–µ—á–µ–Ω–∏–µ'
            }
    
    # –î–æ–±–∞–≤–ª—è–µ–º –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é –æ —Å–µ–≥–º–µ–Ω—Ç–∞—Ö
    print("üè∑Ô∏è –î–æ–±–∞–≤–ª–µ–Ω–∏–µ –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–∏ –æ —Å–µ–≥–º–µ–Ω—Ç–∞—Ö...")
    segments_df['segment_name'] = segments_df['cluster'].map(lambda x: cluster_to_segment.get(x, {}).get('segment_name', '–ù–µ–∏–∑–≤–µ—Å—Ç–Ω—ã–π'))
    segments_df['segment_emoji'] = segments_df['cluster'].map(lambda x: cluster_to_segment.get(x, {}).get('segment_emoji', '‚ùì'))
    segments_df['segment_description'] = segments_df['cluster'].map(lambda x: cluster_to_segment.get(x, {}).get('segment_description', '–û–ø–∏—Å–∞–Ω–∏–µ –Ω–µ–¥–æ—Å—Ç—É–ø–Ω–æ'))
    segments_df['business_strategy'] = segments_df['cluster'].map(lambda x: cluster_to_segment.get(x, {}).get('business_strategy', '–°—Ç—Ä–∞—Ç–µ–≥–∏—è –Ω–µ –æ–ø—Ä–µ–¥–µ–ª–µ–Ω–∞'))
    
    # –î–æ–±–∞–≤–ª—è–µ–º –∫–∞—Ç–µ–≥–æ—Ä–∏–∏ –¥–ª—è —á–∏—Å–ª–æ–≤—ã—Ö –∑–Ω–∞—á–µ–Ω–∏–π
    print("üìà –î–æ–±–∞–≤–ª–µ–Ω–∏–µ –∫–∞—Ç–µ–≥–æ—Ä–∏–π...")
    
    # –ö–∞—Ç–µ–≥–æ—Ä–∏–∏ –ø–æ —Ä–∞–∑–º–µ—Ä—É —Ç—Ä–∞–Ω–∑–∞–∫—Ü–∏–π
    segments_df['transaction_volume_category'] = pd.cut(
        segments_df['total_transactions'], 
        bins=[0, 1000, 5000, 10000, float('inf')],
        labels=['–ù–∏–∑–∫–∏–π', '–°—Ä–µ–¥–Ω–∏–π', '–í—ã—Å–æ–∫–∏–π', '–û—á–µ–Ω—å –≤—ã—Å–æ–∫–∏–π']
    )
    
    # –ö–∞—Ç–µ–≥–æ—Ä–∏–∏ –ø–æ —Å—É–º–º–µ –æ–±–æ—Ä–æ—Ç–∞
    segments_df['revenue_category'] = pd.cut(
        segments_df['total_amount'], 
        bins=[0, 50000000, 100000000, 200000000, float('inf')],
        labels=['–ù–∏–∑–∫–∏–π', '–°—Ä–µ–¥–Ω–∏–π', '–í—ã—Å–æ–∫–∏–π', '–ü—Ä–µ–º–∏—É–º']
    )
    
    # –ö–∞—Ç–µ–≥–æ—Ä–∏–∏ –ø–æ —Å—Ä–µ–¥–Ω–µ–º—É —á–µ–∫—É
    segments_df['avg_ticket_category'] = pd.cut(
        segments_df['avg_amount'], 
        bins=[0, 15000, 25000, 40000, float('inf')],
        labels=['–≠–∫–æ–Ω–æ–º', '–°—Ç–∞–Ω–¥–∞—Ä—Ç', '–ö–æ–º—Ñ–æ—Ä—Ç', '–ü—Ä–µ–º–∏—É–º']
    )
    
    # –î–æ–±–∞–≤–ª—è–µ–º –≤—Ä–µ–º–µ–Ω–Ω—ã–µ –º–µ—Ç–∫–∏
    segments_df['analysis_date'] = datetime.now().strftime('%Y-%m-%d')
    segments_df['analysis_timestamp'] = datetime.now().isoformat()
    
    # –î–æ–±–∞–≤–ª—è–µ–º –º–µ—Ç–∞–¥–∞–Ω–Ω—ã–µ –º–æ–¥–µ–ª–∏
    segments_df['model_type'] = 'K-means'
    segments_df['model_version'] = '1.0'
    segments_df['silhouette_score'] = 0.661
    segments_df['n_clusters'] = 2
    
    # –ü–µ—Ä–µ—É–ø–æ—Ä—è–¥–æ—á–∏–≤–∞–µ–º –∫–æ–ª–æ–Ω–∫–∏ –¥–ª—è –ª—É—á—à–µ–π —á–∏—Ç–∞–µ–º–æ—Å—Ç–∏
    column_order = [
        'card_id', 'cluster', 'segment_name', 'segment_emoji', 'segment_description', 'business_strategy',
        'total_transactions', 'transaction_volume_category',
        'total_amount', 'revenue_category', 
        'avg_amount', 'avg_ticket_category',
        'median_amount', 'std_amount', 'min_amount', 'max_amount',
        'preferred_hour', 'preferred_day', 
        'unique_merchants', 'unique_categories', 'unique_cities',
        'purchase_count', 'preferred_pos_mode', 'preferred_wallet',
        'amount_range', 'purchase_ratio', 'avg_merchants_per_transaction',
        'spending_consistency', 'activity_level', 'spending_level',
        'analysis_date', 'analysis_timestamp',
        'model_type', 'model_version', 'silhouette_score', 'n_clusters'
    ]
    
    segments_df = segments_df[column_order]
    
    # –°–æ–∑–¥–∞–µ–º –ø–∞–ø–∫—É results –µ—Å–ª–∏ –µ—ë –Ω–µ—Ç
    os.makedirs('results', exist_ok=True)
    
    # –°–æ—Ö—Ä–∞–Ω—è–µ–º –≤ —Ñ–æ—Ä–º–∞—Ç–µ parquet
    output_path = 'results/customer_segmentation_results.parquet'
    print(f"üíæ –°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ –≤ —Ñ–∞–π–ª: {output_path}")
    
    segments_df.to_parquet(
        output_path,
        engine='pyarrow',
        compression='snappy',
        index=False
    )
    
    # –°–æ–∑–¥–∞–µ–º –¥–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω—ã–π —Ñ–∞–π–ª —Å –º–µ—Ç–∞–¥–∞–Ω–Ω—ã–º–∏
    metadata = {
        'dataset_info': {
            'name': 'Customer Segmentation Results',
            'description': '–†–µ–∑—É–ª—å—Ç–∞—Ç—ã —Å–µ–≥–º–µ–Ω—Ç–∞—Ü–∏–∏ –±–∞–Ω–∫–æ–≤—Å–∫–∏—Ö –∫–ª–∏–µ–Ω—Ç–æ–≤ —Å –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ–º –º–∞—à–∏–Ω–Ω–æ–≥–æ –æ–±—É—á–µ–Ω–∏—è',
            'total_customers': len(segments_df),
            'analysis_date': datetime.now().strftime('%Y-%m-%d'),
            'model_used': 'K-means clustering',
            'silhouette_score': 0.661,
            'n_clusters': 2
        },
        'segments_summary': {
            'segment_0': {
                'name': '–û–±—ã—á–Ω—ã–µ –∫–ª–∏–µ–Ω—Ç—ã',
                'emoji': 'üîÑ',
                'count': len(segments_df[segments_df['cluster'] == 0]),
                'percentage': round(len(segments_df[segments_df['cluster'] == 0]) / len(segments_df) * 100, 2)
            },
            'segment_1': {
                'name': '–°–ø—è—â–∏–µ –∫–ª–∏–µ–Ω—Ç—ã',
                'emoji': 'üò¥', 
                'count': len(segments_df[segments_df['cluster'] == 1]),
                'percentage': round(len(segments_df[segments_df['cluster'] == 1]) / len(segments_df) * 100, 2)
            }
        },
        'data_schema': {
            'card_id': '–£–Ω–∏–∫–∞–ª—å–Ω—ã–π –∏–¥–µ–Ω—Ç–∏—Ñ–∏–∫–∞—Ç–æ—Ä –∫–ª–∏–µ–Ω—Ç–∞',
            'cluster': '–ù–æ–º–µ—Ä –∫–ª–∞—Å—Ç–µ—Ä–∞ (0 –∏–ª–∏ 1)',
            'segment_name': '–ù–∞–∑–≤–∞–Ω–∏–µ —Å–µ–≥–º–µ–Ω—Ç–∞',
            'segment_emoji': '–≠–º–æ–¥–∑–∏ —Å–µ–≥–º–µ–Ω—Ç–∞',
            'segment_description': '–û–ø–∏—Å–∞–Ω–∏–µ —Å–µ–≥–º–µ–Ω—Ç–∞',
            'business_strategy': '–ë–∏–∑–Ω–µ—Å-—Å—Ç—Ä–∞—Ç–µ–≥–∏—è –¥–ª—è —Å–µ–≥–º–µ–Ω—Ç–∞',
            'total_transactions': '–û–±—â–µ–µ –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ —Ç—Ä–∞–Ω–∑–∞–∫—Ü–∏–π',
            'total_amount': '–û–±—â–∞—è —Å—É–º–º–∞ —Ç—Ä–∞–Ω–∑–∞–∫—Ü–∏–π (—Ç–µ–Ω–≥–µ)',
            'avg_amount': '–°—Ä–µ–¥–Ω—è—è —Å—É–º–º–∞ —Ç—Ä–∞–Ω–∑–∞–∫—Ü–∏–∏ (—Ç–µ–Ω–≥–µ)',
            'preferred_hour': '–ü—Ä–µ–¥–ø–æ—á–∏—Ç–∞–µ–º—ã–π —á–∞—Å –¥–ª—è —Ç—Ä–∞–Ω–∑–∞–∫—Ü–∏–π',
            'preferred_day': '–ü—Ä–µ–¥–ø–æ—á–∏—Ç–∞–µ–º—ã–π –¥–µ–Ω—å –Ω–µ–¥–µ–ª–∏',
            'unique_merchants': '–ö–æ–ª–∏—á–µ—Å—Ç–≤–æ —É–Ω–∏–∫–∞–ª—å–Ω—ã—Ö –º–µ—Ä—á–∞–Ω—Ç–æ–≤',
            'unique_categories': '–ö–æ–ª–∏—á–µ—Å—Ç–≤–æ —É–Ω–∏–∫–∞–ª—å–Ω—ã—Ö –∫–∞—Ç–µ–≥–æ—Ä–∏–π',
            'preferred_pos_mode': '–ü—Ä–µ–¥–ø–æ—á–∏—Ç–∞–µ–º—ã–π —Å–ø–æ—Å–æ–± –æ–ø–ª–∞—Ç—ã',
            'preferred_wallet': '–ü—Ä–µ–¥–ø–æ—á–∏—Ç–∞–µ–º—ã–π –∫–æ—à–µ–ª–µ–∫',
            'activity_level': '–£—Ä–æ–≤–µ–Ω—å –∞–∫—Ç–∏–≤–Ω–æ—Å—Ç–∏',
            'spending_level': '–£—Ä–æ–≤–µ–Ω—å —Ç—Ä–∞—Ç'
        },
        'file_info': {
            'format': 'Apache Parquet',
            'compression': 'Snappy',
            'engine': 'PyArrow',
            'file_size_mb': round(os.path.getsize(output_path) / (1024 * 1024), 2),
            'created_at': datetime.now().isoformat()
        }
    }
    
    # –°–æ—Ö—Ä–∞–Ω—è–µ–º –º–µ—Ç–∞–¥–∞–Ω–Ω—ã–µ
    metadata_path = 'results/customer_segmentation_metadata.json'
    with open(metadata_path, 'w', encoding='utf-8') as f:
        json.dump(metadata, f, ensure_ascii=False, indent=2)
    
    # –í—ã–≤–æ–¥–∏–º —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫—É
    print("\n‚úÖ –§–∞–π–ª —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤ —Å–µ–≥–º–µ–Ω—Ç–∞—Ü–∏–∏ —É—Å–ø–µ—à–Ω–æ —Å–æ–∑–¥–∞–Ω!")
    print(f"üìÅ –û—Å–Ω–æ–≤–Ω–æ–π —Ñ–∞–π–ª: {output_path}")
    print(f"üìã –ú–µ—Ç–∞–¥–∞–Ω–Ω—ã–µ: {metadata_path}")
    print(f"üìä –†–∞–∑–º–µ—Ä —Ñ–∞–π–ª–∞: {metadata['file_info']['file_size_mb']} MB")
    print(f"üë• –í—Å–µ–≥–æ –∫–ª–∏–µ–Ω—Ç–æ–≤: {metadata['dataset_info']['total_customers']:,}")
    print("\nüìà –†–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ –ø–æ —Å–µ–≥–º–µ–Ω—Ç–∞–º:")
    for segment_id, segment_info in metadata['segments_summary'].items():
        print(f"   {segment_info['emoji']} {segment_info['name']}: {segment_info['count']:,} ({segment_info['percentage']}%)")
    
    print(f"\nüîç –°—Ç—Ä—É–∫—Ç—É—Ä–∞ –¥–∞–Ω–Ω—ã—Ö:")
    print(f"   üìã –ö–æ–ª–æ–Ω–æ–∫: {len(segments_df.columns)}")
    print(f"   üìä –°—Ç—Ä–æ–∫: {len(segments_df):,}")
    print(f"   üíæ –§–æ—Ä–º–∞—Ç: Apache Parquet (Snappy compression)")
    
    return output_path, metadata_path

if __name__ == "__main__":
    try:
        parquet_file, metadata_file = create_segmentation_parquet()
        print(f"\nüéâ –ì–æ—Ç–æ–≤–æ! –†–µ–∑—É–ª—å—Ç–∞—Ç—ã —Å–µ–≥–º–µ–Ω—Ç–∞—Ü–∏–∏ —Å–æ—Ö—Ä–∞–Ω–µ–Ω—ã –≤ —Ñ–æ—Ä–º–∞—Ç–µ .parquet")
        print(f"üìÇ –§–∞–π–ª—ã –≥–æ—Ç–æ–≤—ã –¥–ª—è –ø–µ—Ä–µ–¥–∞—á–∏ –∏ –∞–Ω–∞–ª–∏–∑–∞")
    except Exception as e:
        print(f"‚ùå –û—à–∏–±–∫–∞ –ø—Ä–∏ —Å–æ–∑–¥–∞–Ω–∏–∏ —Ñ–∞–π–ª–∞: {e}")
        print("üí° –£–±–µ–¥–∏—Ç–µ—Å—å, —á—Ç–æ —É—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω–∞ –±–∏–±–ª–∏–æ—Ç–µ–∫–∞ pyarrow:")
        print("   pip install pyarrow") 