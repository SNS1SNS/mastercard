"""
–ú–æ–¥—É–ª—å –¥–ª—è –∫–ª–∞—Å—Ç–µ—Ä–∏–∑–∞—Ü–∏–∏ –∫–ª–∏–µ–Ω—Ç–æ–≤ —Å —Ä–∞–∑–ª–∏—á–Ω—ã–º–∏ –∞–ª–≥–æ—Ä–∏—Ç–º–∞–º–∏
"""

import numpy as np
import pandas as pd
import matplotlib
matplotlib.use('Agg')  
import matplotlib.pyplot as plt
import seaborn as sns
from typing import Dict, List, Tuple, Any
from sklearn.cluster import KMeans, DBSCAN, AgglomerativeClustering
from sklearn.mixture import GaussianMixture
from sklearn.metrics import silhouette_score, calinski_harabasz_score, davies_bouldin_score
from sklearn.decomposition import PCA
import warnings
warnings.filterwarnings('ignore')

from config import config

class ClusteringModels:
    """–ö–ª–∞—Å—Å –¥–ª—è —Ä–∞–∑–ª–∏—á–Ω—ã—Ö –∞–ª–≥–æ—Ä–∏—Ç–º–æ–≤ –∫–ª–∞—Å—Ç–µ—Ä–∏–∑–∞—Ü–∏–∏"""
    
    def __init__(self, scaled_features: np.ndarray, feature_names: List[str]):
        """–ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è —Å –ø–æ–¥–≥–æ—Ç–æ–≤–ª–µ–Ω–Ω—ã–º–∏ –¥–∞–Ω–Ω—ã–º–∏"""
        self.scaled_features = scaled_features
        self.feature_names = feature_names
        self.models = {}
        self.results = {}
        self.optimal_clusters = {}
        
    def get_algorithm_descriptions(self) -> Dict[str, Dict[str, str]]:
        """–û–ø–∏—Å–∞–Ω–∏—è –∞–ª–≥–æ—Ä–∏—Ç–º–æ–≤ –∫–ª–∞—Å—Ç–µ—Ä–∏–∑–∞—Ü–∏–∏"""
        return {
            'kmeans': {
                'name': 'K-Means',
                'description': '–†–∞–∑–¥–µ–ª—è–µ—Ç –¥–∞–Ω–Ω—ã–µ –Ω–∞ k –∫–ª–∞—Å—Ç–µ—Ä–æ–≤, –º–∏–Ω–∏–º–∏–∑–∏—Ä—É—è –≤–Ω—É—Ç—Ä–∏–∫–ª–∞—Å—Ç–µ—Ä–Ω—É—é –¥–∏—Å–ø–µ—Ä—Å–∏—é',
                'pros': [
                    '–ü—Ä–æ—Å—Ç–æ—Ç–∞ –∏–Ω—Ç–µ—Ä–ø—Ä–µ—Ç–∞—Ü–∏–∏ –∏ —Ä–µ–∞–ª–∏–∑–∞—Ü–∏–∏',
                    '–ë—ã—Å—Ç—Ä–∞—è —Ä–∞–±–æ—Ç–∞ –Ω–∞ –±–æ–ª—å—à–∏—Ö –¥–∞–Ω–Ω—ã—Ö',
                    '–ß–µ—Ç–∫–∏–µ —Ü–µ–Ω—Ç—Ä–æ–∏–¥—ã –∫–ª–∞—Å—Ç–µ—Ä–æ–≤',
                    '–î–µ—Ç–µ—Ä–º–∏–Ω–∏—Ä–æ–≤–∞–Ω–Ω—ã–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã',
                    '–•–æ—Ä–æ—à–æ —Ä–∞–±–æ—Ç–∞–µ—Ç —Å –≥–ª–æ–±—É–ª—è—Ä–Ω—ã–º–∏ –∫–ª–∞—Å—Ç–µ—Ä–∞–º–∏'
                ],
                'cons': [
                    '–¢—Ä–µ–±—É–µ—Ç –ø—Ä–µ–¥–≤–∞—Ä–∏—Ç–µ–ª—å–Ω–æ–≥–æ –∑–∞–¥–∞–Ω–∏—è –∫–æ–ª–∏—á–µ—Å—Ç–≤–∞ –∫–ª–∞—Å—Ç–µ—Ä–æ–≤',
                    '–ß—É–≤—Å—Ç–≤–∏—Ç–µ–ª–µ–Ω –∫ –≤—ã–±—Ä–æ—Å–∞–º',
                    '–ü—Ä–µ–¥–ø–æ–ª–∞–≥–∞–µ—Ç —Å—Ñ–µ—Ä–∏—á–µ—Å–∫—É—é —Ñ–æ—Ä–º—É –∫–ª–∞—Å—Ç–µ—Ä–æ–≤',
                    '–ß—É–≤—Å—Ç–≤–∏—Ç–µ–ª–µ–Ω –∫ –º–∞—Å—à—Ç–∞–±—É –ø—Ä–∏–∑–Ω–∞–∫–æ–≤'
                ],
                'best_for': '–ë–∏–∑–Ω–µ—Å-—Å–µ–≥–º–µ–Ω—Ç–∞—Ü–∏—è —Å —á–µ—Ç–∫–∏–º–∏ –≥—Ä–∞–Ω–∏—Ü–∞–º–∏ –º–µ–∂–¥—É –≥—Ä—É–ø–ø–∞–º–∏ –∫–ª–∏–µ–Ω—Ç–æ–≤'
            },
            'dbscan': {
                'name': 'DBSCAN',
                'description': '–ù–∞—Ö–æ–¥–∏—Ç –∫–ª–∞—Å—Ç–µ—Ä—ã –ø—Ä–æ–∏–∑–≤–æ–ª—å–Ω–æ–π —Ñ–æ—Ä–º—ã –Ω–∞ –æ—Å–Ω–æ–≤–µ –ø–ª–æ—Ç–Ω–æ—Å—Ç–∏ —Ç–æ—á–µ–∫',
                'pros': [
                    '–ê–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏ –æ–ø—Ä–µ–¥–µ–ª—è–µ—Ç –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ –∫–ª–∞—Å—Ç–µ—Ä–æ–≤',
                    '–ù–∞—Ö–æ–¥–∏—Ç –∫–ª–∞—Å—Ç–µ—Ä—ã –ø—Ä–æ–∏–∑–≤–æ–ª—å–Ω–æ–π —Ñ–æ—Ä–º—ã',
                    '–£—Å—Ç–æ–π—á–∏–≤ –∫ –≤—ã–±—Ä–æ—Å–∞–º',
                    '–í—ã–¥–µ–ª—è–µ—Ç –∞–Ω–æ–º–∞–ª—å–Ω—ã–µ —Ç–æ—á–∫–∏'
                ],
                'cons': [
                    '–°–ª–æ–∂–Ω–æ—Å—Ç—å –ø–æ–¥–±–æ—Ä–∞ –ø–∞—Ä–∞–º–µ—Ç—Ä–æ–≤ eps –∏ min_samples',
                    '–ü–ª–æ—Ö–æ —Ä–∞–±–æ—Ç–∞–µ—Ç —Å –∫–ª–∞—Å—Ç–µ—Ä–∞–º–∏ —Ä–∞–∑–Ω–æ–π –ø–ª–æ—Ç–Ω–æ—Å—Ç–∏',
                    '–ß—É–≤—Å—Ç–≤–∏—Ç–µ–ª–µ–Ω –∫ —Ä–∞–∑–º–µ—Ä–Ω–æ—Å—Ç–∏ –¥–∞–Ω–Ω—ã—Ö',
                    '–ú–æ–∂–µ—Ç —Å–æ–∑–¥–∞–≤–∞—Ç—å —Å–ª–∏—à–∫–æ–º –º–Ω–æ–≥–æ –º–µ–ª–∫–∏—Ö –∫–ª–∞—Å—Ç–µ—Ä–æ–≤'
                ],
                'best_for': '–í—ã—è–≤–ª–µ–Ω–∏–µ –∞–Ω–æ–º–∞–ª—å–Ω—ã—Ö –∫–ª–∏–µ–Ω—Ç–æ–≤ –∏ –Ω–µ—Å—Ç–∞–Ω–¥–∞—Ä—Ç–Ω—ã—Ö –ø–∞—Ç—Ç–µ—Ä–Ω–æ–≤ –ø–æ–≤–µ–¥–µ–Ω–∏—è'
            },
            'gaussian_mixture': {
                'name': 'Gaussian Mixture Model',
                'description': '–ú–æ–¥–µ–ª–∏—Ä—É–µ—Ç –¥–∞–Ω–Ω—ã–µ –∫–∞–∫ —Å–º–µ—Å—å –≥–∞—É—Å—Å–æ–≤—ã—Ö —Ä–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–π',
                'pros': [
                    '–ú—è–≥–∫–∞—è –∫–ª–∞—Å—Ç–µ—Ä–∏–∑–∞—Ü–∏—è (–≤–µ—Ä–æ—è—Ç–Ω–æ—Å—Ç–∏ –ø—Ä–∏–Ω–∞–¥–ª–µ–∂–Ω–æ—Å—Ç–∏)',
                    '–ì–∏–±–∫–æ—Å—Ç—å –≤ —Ñ–æ—Ä–º–µ –∫–ª–∞—Å—Ç–µ—Ä–æ–≤',
                    '–°—Ç–∞—Ç–∏—Å—Ç–∏—á–µ—Å–∫–∞—è –∏–Ω—Ç–µ—Ä–ø—Ä–µ—Ç–∞—Ü–∏—è',
                    '–ú–æ–∂–µ—Ç –º–æ–¥–µ–ª–∏—Ä–æ–≤–∞—Ç—å –ø–µ—Ä–µ–∫—Ä—ã–≤–∞—é—â–∏–µ—Å—è –∫–ª–∞—Å—Ç–µ—Ä—ã'
                ],
                'cons': [
                    '–¢—Ä–µ–±—É–µ—Ç –ø—Ä–µ–¥–≤–∞—Ä–∏—Ç–µ–ª—å–Ω–æ–≥–æ –∑–∞–¥–∞–Ω–∏—è –∫–æ–ª–∏—á–µ—Å—Ç–≤–∞ –∫–æ–º–ø–æ–Ω–µ–Ω—Ç',
                    '–í—ã—á–∏—Å–ª–∏—Ç–µ–ª—å–Ω–æ —Å–ª–æ–∂–Ω–µ–µ K-means',
                    '–ú–æ–∂–µ—Ç –ø–µ—Ä–µ–æ–±—É—á–∞—Ç—å—Å—è –Ω–∞ –º–∞–ª—ã—Ö –≤—ã–±–æ—Ä–∫–∞—Ö',
                    '–ß—É–≤—Å—Ç–≤–∏—Ç–µ–ª–µ–Ω –∫ –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏–∏'
                ],
                'best_for': '–ö–æ–≥–¥–∞ –∫–ª–∏–µ–Ω—Ç—ã –º–æ–≥—É—Ç –ø—Ä–∏–Ω–∞–¥–ª–µ–∂–∞—Ç—å –∫ –Ω–µ—Å–∫–æ–ª—å–∫–∏–º —Å–µ–≥–º–µ–Ω—Ç–∞–º –æ–¥–Ω–æ–≤—Ä–µ–º–µ–Ω–Ω–æ'
            },
            'hierarchical': {
                'name': 'Agglomerative Clustering',
                'description': '–ò–µ—Ä–∞—Ä—Ö–∏—á–µ—Å–∫–∞—è –∫–ª–∞—Å—Ç–µ—Ä–∏–∑–∞—Ü–∏—è —Å–Ω–∏–∑—É –≤–≤–µ—Ä—Ö',
                'pros': [
                    '–°–æ–∑–¥–∞–µ—Ç –∏–µ—Ä–∞—Ä—Ö–∏—é –∫–ª–∞—Å—Ç–µ—Ä–æ–≤',
                    '–ù–µ —Ç—Ä–µ–±—É–µ—Ç –ø—Ä–µ–¥–≤–∞—Ä–∏—Ç–µ–ª—å–Ω–æ–≥–æ –∑–∞–¥–∞–Ω–∏—è –∫–æ–ª–∏—á–µ—Å—Ç–≤–∞ –∫–ª–∞—Å—Ç–µ—Ä–æ–≤',
                    '–î–µ—Ç–µ—Ä–º–∏–Ω–∏—Ä–æ–≤–∞–Ω–Ω—ã–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã',
                    '–•–æ—Ä–æ—à–∞—è –≤–∏–∑—É–∞–ª–∏–∑–∞—Ü–∏—è —á–µ—Ä–µ–∑ –¥–µ–Ω–¥—Ä–æ–≥—Ä–∞–º–º—É'
                ],
                'cons': [
                    '–í—ã—Å–æ–∫–∞—è –≤—ã—á–∏—Å–ª–∏—Ç–µ–ª—å–Ω–∞—è —Å–ª–æ–∂–Ω–æ—Å—Ç—å O(n¬≥)',
                    '–ß—É–≤—Å—Ç–≤–∏—Ç–µ–ª–µ–Ω –∫ –≤—ã–±—Ä–æ—Å–∞–º',
                    '–°–ª–æ–∂–Ω–æ—Å—Ç—å –≤—ã–±–æ—Ä–∞ –∫—Ä–∏—Ç–µ—Ä–∏—è —Å–≤—è–∑–∏',
                    '–ù–µ –ø–æ–¥—Ö–æ–¥–∏—Ç –¥–ª—è –æ—á–µ–Ω—å –±–æ–ª—å—à–∏—Ö –¥–∞–Ω–Ω—ã—Ö'
                ],
                'best_for': '–ò—Å—Å–ª–µ–¥–æ–≤–∞—Ç–µ–ª—å—Å–∫–∏–π –∞–Ω–∞–ª–∏–∑ –¥–ª—è –ø–æ–Ω–∏–º–∞–Ω–∏—è —Å—Ç—Ä—É–∫—Ç—É—Ä—ã –¥–∞–Ω–Ω—ã—Ö'
            }
        }
    
    def find_optimal_clusters_kmeans(self, max_clusters: int = None) -> int:
        """–ü–æ–∏—Å–∫ –æ–ø—Ç–∏–º–∞–ª—å–Ω–æ–≥–æ –∫–æ–ª–∏—á–µ—Å—Ç–≤–∞ –∫–ª–∞—Å—Ç–µ—Ä–æ–≤ –¥–ª—è K-means"""
        if max_clusters is None:
            max_clusters = config.model.max_clusters
            
        print(f"\nüîç –ü–æ–∏—Å–∫ –æ–ø—Ç–∏–º–∞–ª—å–Ω–æ–≥–æ –∫–æ–ª–∏—á–µ—Å—Ç–≤–∞ –∫–ª–∞—Å—Ç–µ—Ä–æ–≤ –¥–ª—è K-means (–¥–æ {max_clusters})...")
        
        metrics = {
            'inertia': [],
            'silhouette': [],
            'calinski_harabasz': [],
            'davies_bouldin': []
        }
        
        K_range = range(2, max_clusters + 1)
        
        for k in K_range:
            
            kmeans = KMeans(
                n_clusters=k, 
                random_state=config.model.random_state, 
                n_init=config.model.n_init
            )
            cluster_labels = kmeans.fit_predict(self.scaled_features)
            
            
            metrics['inertia'].append(kmeans.inertia_)
            metrics['silhouette'].append(silhouette_score(self.scaled_features, cluster_labels))
            metrics['calinski_harabasz'].append(calinski_harabasz_score(self.scaled_features, cluster_labels))
            metrics['davies_bouldin'].append(davies_bouldin_score(self.scaled_features, cluster_labels))
        
        
        self._plot_optimization_metrics(K_range, metrics, 'K-means')
        
        
        
        optimal_k = K_range[np.argmax(metrics['silhouette'])]
        
        
        elbow_k = self._find_elbow_point(metrics['inertia'])
        
        print(f"üìä –†–µ–∑—É–ª—å—Ç–∞—Ç—ã –æ–ø—Ç–∏–º–∏–∑–∞—Ü–∏–∏:")
        print(f"   –°–∏–ª—É—ç—Ç–Ω—ã–π –∞–Ω–∞–ª–∏–∑ —Ä–µ–∫–æ–º–µ–Ω–¥—É–µ—Ç: {optimal_k} –∫–ª–∞—Å—Ç–µ—Ä–æ–≤")
        print(f"   –ú–µ—Ç–æ–¥ –ª–æ–∫—Ç—è —Ä–µ–∫–æ–º–µ–Ω–¥—É–µ—Ç: {elbow_k} –∫–ª–∞—Å—Ç–µ—Ä–æ–≤")
        print(f"   –ú–∞–∫—Å–∏–º–∞–ª—å–Ω—ã–π –∏–Ω–¥–µ–∫—Å –ö–∞–ª–∏–Ω—Å–∫–∏-–•–∞—Ä–∞–±–∞—à–∞: {K_range[np.argmax(metrics['calinski_harabasz'])]} –∫–ª–∞—Å—Ç–µ—Ä–æ–≤")
        print(f"   –ú–∏–Ω–∏–º–∞–ª—å–Ω—ã–π –∏–Ω–¥–µ–∫—Å –î—ç–≤–∏—Å–∞-–ë–æ–ª–¥–∏–Ω–∞: {K_range[np.argmin(metrics['davies_bouldin'])]} –∫–ª–∞—Å—Ç–µ—Ä–æ–≤")
        
        self.optimal_clusters['kmeans'] = optimal_k
        return optimal_k
    
    def _find_elbow_point(self, inertias: List[float]) -> int:
        """–ü–æ–∏—Å–∫ —Ç–æ—á–∫–∏ –ª–æ–∫—Ç—è –º–µ—Ç–æ–¥–æ–º –º–∞–∫—Å–∏–º–∞–ª—å–Ω–æ–π –∫—Ä–∏–≤–∏–∑–Ω—ã"""
        
        x = np.arange(len(inertias))
        y = np.array(inertias)
        
        
        if len(y) > 2:
            second_derivative = np.diff(y, 2)
            elbow_idx = np.argmax(second_derivative) + 2  
            return elbow_idx + 2  
        else:
            return 3  
    
    def _plot_optimization_metrics(self, K_range: range, metrics: Dict, algorithm: str):
        """–í–∏–∑—É–∞–ª–∏–∑–∞—Ü–∏—è –º–µ—Ç—Ä–∏–∫ –æ–ø—Ç–∏–º–∏–∑–∞—Ü–∏–∏"""
        fig, axes = plt.subplots(2, 2, figsize=(15, 10))
        fig.suptitle(f'–û–ø—Ç–∏–º–∏–∑–∞—Ü–∏—è –∫–æ–ª–∏—á–µ—Å—Ç–≤–∞ –∫–ª–∞—Å—Ç–µ—Ä–æ–≤ - {algorithm}', fontsize=16)
        
        
        axes[0, 0].plot(K_range, metrics['inertia'], 'bo-', linewidth=2, markersize=8)
        axes[0, 0].set_title('–ú–µ—Ç–æ–¥ –ª–æ–∫—Ç—è (Inertia)')
        axes[0, 0].set_xlabel('–ö–æ–ª–∏—á–µ—Å—Ç–≤–æ –∫–ª–∞—Å—Ç–µ—Ä–æ–≤')
        axes[0, 0].set_ylabel('–ò–Ω–µ—Ä—Ü–∏—è')
        axes[0, 0].grid(True, alpha=0.3)
        
        
        axes[0, 1].plot(K_range, metrics['silhouette'], 'ro-', linewidth=2, markersize=8)
        axes[0, 1].set_title('–°–∏–ª—É—ç—Ç–Ω—ã–π –∞–Ω–∞–ª–∏–∑')
        axes[0, 1].set_xlabel('–ö–æ–ª–∏—á–µ—Å—Ç–≤–æ –∫–ª–∞—Å—Ç–µ—Ä–æ–≤')
        axes[0, 1].set_ylabel('–°–∏–ª—É—ç—Ç–Ω—ã–π –∫–æ—ç—Ñ—Ñ–∏—Ü–∏–µ–Ω—Ç')
        axes[0, 1].grid(True, alpha=0.3)
        
        
        axes[1, 0].plot(K_range, metrics['calinski_harabasz'], 'go-', linewidth=2, markersize=8)
        axes[1, 0].set_title('–ò–Ω–¥–µ–∫—Å –ö–∞–ª–∏–Ω—Å–∫–∏-–•–∞—Ä–∞–±–∞—à–∞')
        axes[1, 0].set_xlabel('–ö–æ–ª–∏—á–µ—Å—Ç–≤–æ –∫–ª–∞—Å—Ç–µ—Ä–æ–≤')
        axes[1, 0].set_ylabel('–ò–Ω–¥–µ–∫—Å CH')
        axes[1, 0].grid(True, alpha=0.3)
        
        
        axes[1, 1].plot(K_range, metrics['davies_bouldin'], 'mo-', linewidth=2, markersize=8)
        axes[1, 1].set_title('–ò–Ω–¥–µ–∫—Å –î—ç–≤–∏—Å–∞-–ë–æ–ª–¥–∏–Ω–∞')
        axes[1, 1].set_xlabel('–ö–æ–ª–∏—á–µ—Å—Ç–≤–æ –∫–ª–∞—Å—Ç–µ—Ä–æ–≤')
        axes[1, 1].set_ylabel('–ò–Ω–¥–µ–∫—Å DB (–º–µ–Ω—å—à–µ = –ª—É—á—à–µ)')
        axes[1, 1].grid(True, alpha=0.3)
        
        plt.tight_layout()
        plt.savefig(config.get_output_path(f'{algorithm.lower()}_optimization.png'), 
                   dpi=config.visualization.dpi, bbox_inches='tight')
        plt.close()
        print(f"‚úÖ –ì—Ä–∞—Ñ–∏–∫ –æ–ø—Ç–∏–º–∏–∑–∞—Ü–∏–∏ {algorithm} —Å–æ—Ö—Ä–∞–Ω–µ–Ω")
    
    def fit_kmeans(self, n_clusters: int = None) -> Dict[str, Any]:
        """–û–±—É—á–µ–Ω–∏–µ K-means –º–æ–¥–µ–ª–∏"""
        if n_clusters is None:
            n_clusters = self.find_optimal_clusters_kmeans()
        
        print(f"\nüéØ –û–±—É—á–µ–Ω–∏–µ K-means —Å {n_clusters} –∫–ª–∞—Å—Ç–µ—Ä–∞–º–∏...")
        
        
        kmeans = KMeans(
            n_clusters=n_clusters,
            random_state=config.model.random_state,
            n_init=config.model.n_init
        )
        cluster_labels = kmeans.fit_predict(self.scaled_features)
        
        
        metrics = self._calculate_clustering_metrics(cluster_labels)
        
        
        self.models['kmeans'] = kmeans
        self.results['kmeans'] = {
            'labels': cluster_labels,
            'n_clusters': n_clusters,
            'metrics': metrics,
            'centroids': kmeans.cluster_centers_
        }
        
        print(f"‚úÖ K-means –æ–±—É—á–µ–Ω —É—Å–ø–µ—à–Ω–æ")
        self._print_metrics(metrics, 'K-means')
        
        return self.results['kmeans']
    
    def fit_dbscan(self, eps: float = None, min_samples: int = None) -> Dict[str, Any]:
        """–û–±—É—á–µ–Ω–∏–µ DBSCAN –º–æ–¥–µ–ª–∏"""
        if eps is None:
            eps = self._estimate_eps()
        if min_samples is None:
            min_samples = max(2, int(np.log(len(self.scaled_features))))
        
        print(f"\nüéØ –û–±—É—á–µ–Ω–∏–µ DBSCAN (eps={eps:.3f}, min_samples={min_samples})...")
        
        
        dbscan = DBSCAN(eps=eps, min_samples=min_samples)
        cluster_labels = dbscan.fit_predict(self.scaled_features)
        
        
        n_clusters = len(set(cluster_labels)) - (1 if -1 in cluster_labels else 0)
        n_noise = list(cluster_labels).count(-1)
        
        print(f"   –ù–∞–π–¥–µ–Ω–æ –∫–ª–∞—Å—Ç–µ—Ä–æ–≤: {n_clusters}")
        print(f"   –í—ã–±—Ä–æ—Å–æ–≤ (—à—É–º): {n_noise} ({n_noise/len(cluster_labels)*100:.1f}%)")
        
        if n_clusters < 2:
            print("‚ö†Ô∏è DBSCAN –Ω–∞—à–µ–ª –º–µ–Ω–µ–µ 2 –∫–ª–∞—Å—Ç–µ—Ä–æ–≤. –ü–æ–ø—Ä–æ–±—É–π—Ç–µ –∏–∑–º–µ–Ω–∏—Ç—å –ø–∞—Ä–∞–º–µ—Ç—Ä—ã.")
            return None
        
        
        if n_noise < len(cluster_labels):
            valid_mask = cluster_labels != -1
            if np.sum(valid_mask) > 0 and len(set(cluster_labels[valid_mask])) > 1:
                metrics = self._calculate_clustering_metrics(
                    cluster_labels[valid_mask], 
                    self.scaled_features[valid_mask]
                )
            else:
                metrics = {'silhouette': 0, 'calinski_harabasz': 0, 'davies_bouldin': float('inf')}
        else:
            metrics = {'silhouette': 0, 'calinski_harabasz': 0, 'davies_bouldin': float('inf')}
        
        
        self.models['dbscan'] = dbscan
        self.results['dbscan'] = {
            'labels': cluster_labels,
            'n_clusters': n_clusters,
            'n_noise': n_noise,
            'metrics': metrics,
            'eps': eps,
            'min_samples': min_samples
        }
        
        print(f"‚úÖ DBSCAN –æ–±—É—á–µ–Ω —É—Å–ø–µ—à–Ω–æ")
        self._print_metrics(metrics, 'DBSCAN')
        
        return self.results['dbscan']
    
    def _estimate_eps(self) -> float:
        """–û—Ü–µ–Ω–∫–∞ –ø–∞—Ä–∞–º–µ—Ç—Ä–∞ eps –¥–ª—è DBSCAN"""
        from sklearn.neighbors import NearestNeighbors
        
        
        k = max(2, int(np.log(len(self.scaled_features))))
        neighbors = NearestNeighbors(n_neighbors=k)
        neighbors_fit = neighbors.fit(self.scaled_features)
        distances, indices = neighbors_fit.kneighbors(self.scaled_features)
        
        
        distances = np.sort(distances[:, k-1], axis=0)
        
        
        
        eps = np.percentile(distances, 90)
        
        return eps
    
    def fit_gaussian_mixture(self, n_components: int = None) -> Dict[str, Any]:
        """–û–±—É—á–µ–Ω–∏–µ Gaussian Mixture Model"""
        if n_components is None:
            n_components = self.optimal_clusters.get('kmeans', 4)
        
        print(f"\nüéØ –û–±—É—á–µ–Ω–∏–µ Gaussian Mixture Model —Å {n_components} –∫–æ–º–ø–æ–Ω–µ–Ω—Ç–∞–º–∏...")
        
        
        gmm = GaussianMixture(
            n_components=n_components,
            random_state=config.model.random_state,
            covariance_type='full'
        )
        gmm.fit(self.scaled_features)
        cluster_labels = gmm.predict(self.scaled_features)
        
        
        metrics = self._calculate_clustering_metrics(cluster_labels)
        
        
        metrics['aic'] = gmm.aic(self.scaled_features)
        metrics['bic'] = gmm.bic(self.scaled_features)
        metrics['log_likelihood'] = gmm.score(self.scaled_features)
        
        
        self.models['gaussian_mixture'] = gmm
        self.results['gaussian_mixture'] = {
            'labels': cluster_labels,
            'n_clusters': n_components,
            'metrics': metrics,
            'probabilities': gmm.predict_proba(self.scaled_features),
            'means': gmm.means_,
            'covariances': gmm.covariances_
        }
        
        print(f"‚úÖ Gaussian Mixture Model –æ–±—É—á–µ–Ω —É—Å–ø–µ—à–Ω–æ")
        self._print_metrics(metrics, 'Gaussian Mixture Model')
        
        return self.results['gaussian_mixture']
    
    def _calculate_clustering_metrics(self, labels: np.ndarray, features: np.ndarray = None) -> Dict[str, float]:
        """–†–∞—Å—á–µ—Ç –º–µ—Ç—Ä–∏–∫ –∫–∞—á–µ—Å—Ç–≤–∞ –∫–ª–∞—Å—Ç–µ—Ä–∏–∑–∞—Ü–∏–∏"""
        if features is None:
            features = self.scaled_features
        
        metrics = {}
        
        
        unique_labels = set(labels)
        if len(unique_labels) > 1:
            metrics['silhouette'] = silhouette_score(features, labels)
            metrics['calinski_harabasz'] = calinski_harabasz_score(features, labels)
            metrics['davies_bouldin'] = davies_bouldin_score(features, labels)
        else:
            metrics['silhouette'] = 0
            metrics['calinski_harabasz'] = 0
            metrics['davies_bouldin'] = float('inf')
        
        return metrics
    
    def _print_metrics(self, metrics: Dict[str, float], model_name: str):
        """–í—ã–≤–æ–¥ –º–µ—Ç—Ä–∏–∫ –∫–∞—á–µ—Å—Ç–≤–∞"""
        print(f"üìä –ú–µ—Ç—Ä–∏–∫–∏ –∫–∞—á–µ—Å—Ç–≤–∞ {model_name}:")
        print(f"   –°–∏–ª—É—ç—Ç–Ω—ã–π –∫–æ—ç—Ñ—Ñ–∏—Ü–∏–µ–Ω—Ç: {metrics['silhouette']:.3f}")
        print(f"   –ò–Ω–¥–µ–∫—Å –ö–∞–ª–∏–Ω—Å–∫–∏-–•–∞—Ä–∞–±–∞—à–∞: {metrics['calinski_harabasz']:.2f}")
        print(f"   –ò–Ω–¥–µ–∫—Å –î—ç–≤–∏—Å–∞-–ë–æ–ª–¥–∏–Ω–∞: {metrics['davies_bouldin']:.3f}")
        
        if 'aic' in metrics:
            print(f"   AIC: {metrics['aic']:.2f}")
            print(f"   BIC: {metrics['bic']:.2f}")
            print(f"   Log-likelihood: {metrics['log_likelihood']:.2f}")
    
    def compare_models(self) -> pd.DataFrame:
        """–°—Ä–∞–≤–Ω–µ–Ω–∏–µ –≤—Å–µ—Ö –æ–±—É—á–µ–Ω–Ω—ã—Ö –º–æ–¥–µ–ª–µ–π"""
        print("\nüìä –°–†–ê–í–ù–ï–ù–ò–ï –ú–û–î–ï–õ–ï–ô –ö–õ–ê–°–¢–ï–†–ò–ó–ê–¶–ò–ò")
        print("="*50)
        
        comparison_data = []
        
        for model_name, results in self.results.items():
            if results is not None:
                row = {
                    '–ú–æ–¥–µ–ª—å': model_name.replace('_', ' ').title(),
                    '–ö–æ–ª–∏—á–µ—Å—Ç–≤–æ –∫–ª–∞—Å—Ç–µ—Ä–æ–≤': results['n_clusters'],
                    '–°–∏–ª—É—ç—Ç–Ω—ã–π –∫–æ—ç—Ñ—Ñ–∏—Ü–∏–µ–Ω—Ç': results['metrics']['silhouette'],
                    '–ò–Ω–¥–µ–∫—Å –ö–∞–ª–∏–Ω—Å–∫–∏-–•–∞—Ä–∞–±–∞—à–∞': results['metrics']['calinski_harabasz'],
                    '–ò–Ω–¥–µ–∫—Å –î—ç–≤–∏—Å–∞-–ë–æ–ª–¥–∏–Ω–∞': results['metrics']['davies_bouldin']
                }
                
                
                if 'n_noise' in results:
                    row['–ö–æ–ª–∏—á–µ—Å—Ç–≤–æ –≤—ã–±—Ä–æ—Å–æ–≤'] = results['n_noise']
                if 'aic' in results['metrics']:
                    row['AIC'] = results['metrics']['aic']
                    row['BIC'] = results['metrics']['bic']
                
                comparison_data.append(row)
        
        comparison_df = pd.DataFrame(comparison_data)
        
        if not comparison_df.empty:
            print(comparison_df.round(3).to_string(index=False))
            
            
            best_model_idx = comparison_df['–°–∏–ª—É—ç—Ç–Ω—ã–π –∫–æ—ç—Ñ—Ñ–∏—Ü–∏–µ–Ω—Ç'].idxmax()
            best_model = comparison_df.loc[best_model_idx, '–ú–æ–¥–µ–ª—å']
            best_silhouette = comparison_df.loc[best_model_idx, '–°–∏–ª—É—ç—Ç–Ω—ã–π –∫–æ—ç—Ñ—Ñ–∏—Ü–∏–µ–Ω—Ç']
            
            print(f"\nüèÜ –†–µ–∫–æ–º–µ–Ω–¥—É–µ–º–∞—è –º–æ–¥–µ–ª—å: {best_model}")
            print(f"   –°–∏–ª—É—ç—Ç–Ω—ã–π –∫–æ—ç—Ñ—Ñ–∏—Ü–∏–µ–Ω—Ç: {best_silhouette:.3f}")
            
            
            comparison_df.to_csv(config.get_output_path('model_comparison.csv'), index=False)
            print(f"üíæ –°—Ä–∞–≤–Ω–µ–Ω–∏–µ –º–æ–¥–µ–ª–µ–π —Å–æ—Ö—Ä–∞–Ω–µ–Ω–æ: {config.get_output_path('model_comparison.csv')}")
        
        return comparison_df
    
    def get_best_model(self) -> Tuple[str, Dict[str, Any]]:
        """–ü–æ–ª—É—á–µ–Ω–∏–µ –ª—É—á—à–µ–π –º–æ–¥–µ–ª–∏ –ø–æ —Å–∏–ª—É—ç—Ç–Ω–æ–º—É –∫–æ—ç—Ñ—Ñ–∏—Ü–∏–µ–Ω—Ç—É"""
        if not self.results:
            raise ValueError("–ù–µ—Ç –æ–±—É—á–µ–Ω–Ω—ã—Ö –º–æ–¥–µ–ª–µ–π –¥–ª—è —Å—Ä–∞–≤–Ω–µ–Ω–∏—è")
        
        best_model_name = None
        best_score = -1
        
        for model_name, results in self.results.items():
            if results is not None and results['metrics']['silhouette'] > best_score:
                best_score = results['metrics']['silhouette']
                best_model_name = model_name
        
        return best_model_name, self.results[best_model_name]
    
    def explain_model_choice(self, chosen_model: str) -> str:
        """–û–±—ä—è—Å–Ω–µ–Ω–∏–µ –≤—ã–±–æ—Ä–∞ –º–æ–¥–µ–ª–∏"""
        descriptions = self.get_algorithm_descriptions()
        
        if chosen_model not in descriptions:
            return f"–ú–æ–¥–µ–ª—å {chosen_model} –Ω–µ –Ω–∞–π–¥–µ–Ω–∞ –≤ –æ–ø–∏—Å–∞–Ω–∏—è—Ö"
        
        model_info = descriptions[chosen_model]
        results = self.results.get(chosen_model, {})
        
        explanation = f"""
üéØ –û–ë–û–°–ù–û–í–ê–ù–ò–ï –í–´–ë–û–†–ê –ú–û–î–ï–õ–ò: {model_info['name']}

üìù –û–ø–∏—Å–∞–Ω–∏–µ –∞–ª–≥–æ—Ä–∏—Ç–º–∞:
{model_info['description']}

‚úÖ –ü—Ä–µ–∏–º—É—â–µ—Å—Ç–≤–∞:
"""
        for pro in model_info['pros']:
            explanation += f"‚Ä¢ {pro}\n"
        
        explanation += f"""
‚ö†Ô∏è –ù–µ–¥–æ—Å—Ç–∞—Ç–∫–∏:
"""
        for con in model_info['cons']:
            explanation += f"‚Ä¢ {con}\n"
        
        explanation += f"""
üéØ –õ—É—á—à–µ –≤—Å–µ–≥–æ –ø–æ–¥—Ö–æ–¥–∏—Ç –¥–ª—è:
{model_info['best_for']}

üìä –†–µ–∑—É–ª—å—Ç–∞—Ç—ã –Ω–∞ –Ω–∞—à–∏—Ö –¥–∞–Ω–Ω—ã—Ö:
"""
        if results:
            metrics = results['metrics']
            explanation += f"‚Ä¢ –ö–æ–ª–∏—á–µ—Å—Ç–≤–æ –∫–ª–∞—Å—Ç–µ—Ä–æ–≤: {results['n_clusters']}\n"
            explanation += f"‚Ä¢ –°–∏–ª—É—ç—Ç–Ω—ã–π –∫–æ—ç—Ñ—Ñ–∏—Ü–∏–µ–Ω—Ç: {metrics['silhouette']:.3f}\n"
            explanation += f"‚Ä¢ –ò–Ω–¥–µ–∫—Å –ö–∞–ª–∏–Ω—Å–∫–∏-–•–∞—Ä–∞–±–∞—à–∞: {metrics['calinski_harabasz']:.2f}\n"
            explanation += f"‚Ä¢ –ò–Ω–¥–µ–∫—Å –î—ç–≤–∏—Å–∞-–ë–æ–ª–¥–∏–Ω–∞: {metrics['davies_bouldin']:.3f}\n"
        
        return explanation 