"""
–î–µ–º–æ–Ω—Å—Ç—Ä–∞—Ü–∏–æ–Ω–Ω—ã–π —Å–∫—Ä–∏–ø—Ç –¥–ª—è –±—ã—Å—Ç—Ä–æ–≥–æ —Ç–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏—è —Ñ—É–Ω–∫—Ü–∏–æ–Ω–∞–ª—å–Ω–æ—Å—Ç–∏
—Å–µ–≥–º–µ–Ω—Ç–∞—Ü–∏–∏ –∫–ª–∏–µ–Ω—Ç–æ–≤ –±–∞–Ω–∫–∞
"""

import warnings
warnings.filterwarnings('ignore')

import pandas as pd
import numpy as np
from datetime import datetime
import os

def test_imports():
    """–¢–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ –∏–º–ø–æ—Ä—Ç–∞ –≤—Å–µ—Ö –º–æ–¥—É–ª–µ–π"""
    print("üîç –¢–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ –∏–º–ø–æ—Ä—Ç–∞ –º–æ–¥—É–ª–µ–π...")
    
    try:
        from config import config
        print("   ‚úÖ config.py - OK")
        
        from data_processor import DataProcessor
        print("   ‚úÖ data_processor.py - OK")
        
        from clustering_models import ClusteringModels
        print("   ‚úÖ clustering_models.py - OK")
        
        from segment_analyzer import SegmentAnalyzer
        print("   ‚úÖ segment_analyzer.py - OK")
        
        print("‚úÖ –í—Å–µ –º–æ–¥—É–ª–∏ —É—Å–ø–µ—à–Ω–æ –∏–º–ø–æ—Ä—Ç–∏—Ä–æ–≤–∞–Ω—ã!")
        return True
        
    except ImportError as e:
        print(f"‚ùå –û—à–∏–±–∫–∞ –∏–º–ø–æ—Ä—Ç–∞: {e}")
        return False

def test_config():
    """–¢–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏–∏"""
    print("\nüîß –¢–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏–∏...")
    
    try:
        from config import config
        
        print(f"   üìÅ –§–∞–π–ª –¥–∞–Ω–Ω—ã—Ö: {config.data.data_file}")
        print(f"   üìÅ –ü–∞–ø–∫–∞ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤: {config.data.output_dir}")
        print(f"   üéØ –ü—Ä–∏–∑–Ω–∞–∫–∏ –¥–ª—è –∫–ª–∞—Å—Ç–µ—Ä–∏–∑–∞—Ü–∏–∏: {len(config.features.clustering_features) if config.features.clustering_features else '–ê–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏'}")
        print(f"   ü§ñ –ê–ª–≥–æ—Ä–∏—Ç–º –ø–æ —É–º–æ–ª—á–∞–Ω–∏—é: K-Means")
        print(f"   üìä –°—Ç–∏–ª—å –≤–∏–∑—É–∞–ª–∏–∑–∞—Ü–∏–∏: {config.visualization.style}")
        
        
        if not os.path.exists(config.data.output_dir):
            os.makedirs(config.data.output_dir)
            print(f"   ‚úÖ –°–æ–∑–¥–∞–Ω–∞ –ø–∞–ø–∫–∞ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤: {config.data.output_dir}")
        else:
            print(f"   ‚úÖ –ü–∞–ø–∫–∞ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤ —Å—É—â–µ—Å—Ç–≤—É–µ—Ç: {config.data.output_dir}")
            
        return True
        
    except Exception as e:
        print(f"‚ùå –û—à–∏–±–∫–∞ –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏–∏: {e}")
        return False

def test_data_loading():
    """–¢–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ –∑–∞–≥—Ä—É–∑–∫–∏ –¥–∞–Ω–Ω—ã—Ö"""
    print("\nüìä –¢–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ –∑–∞–≥—Ä—É–∑–∫–∏ –¥–∞–Ω–Ω—ã—Ö...")
    
    try:
        from config import config
        from data_processor import DataProcessor
        
        
        if not os.path.exists(config.data.data_file):
            print(f"‚ùå –§–∞–π–ª –¥–∞–Ω–Ω—ã—Ö –Ω–µ –Ω–∞–π–¥–µ–Ω: {config.data.data_file}")
            return False
        
        
        processor = DataProcessor(config.data.data_file)
        
        print(f"   ‚úÖ –î–∞–Ω–Ω—ã–µ —É—Å–ø–µ—à–Ω–æ –∑–∞–≥—Ä—É–∂–µ–Ω—ã")
        print(f"   üìà –ö–æ–ª–∏—á–µ—Å—Ç–≤–æ —Ç—Ä–∞–Ω–∑–∞–∫—Ü–∏–π: {len(processor.data):,}")
        print(f"   üë• –ö–æ–ª–∏—á–µ—Å—Ç–≤–æ —É–Ω–∏–∫–∞–ª—å–Ω—ã—Ö –∫–ª–∏–µ–Ω—Ç–æ–≤: {processor.data['card_id'].nunique():,}")
        print(f"   üè™ –ö–æ–ª–∏—á–µ—Å—Ç–≤–æ –º–µ—Ä—á–∞–Ω—Ç–æ–≤: {processor.data['merchant_id'].nunique():,}")
        
        return True
        
    except Exception as e:
        print(f"‚ùå –û—à–∏–±–∫–∞ –∑–∞–≥—Ä—É–∑–∫–∏ –¥–∞–Ω–Ω—ã—Ö: {e}")
        return False

def test_feature_creation():
    """–¢–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ —Å–æ–∑–¥–∞–Ω–∏—è –ø—Ä–∏–∑–Ω–∞–∫–æ–≤"""
    print("\nüõ†Ô∏è –¢–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ —Å–æ–∑–¥–∞–Ω–∏—è –ø—Ä–∏–∑–Ω–∞–∫–æ–≤...")
    
    try:
        from config import config
        from data_processor import DataProcessor
        
        processor = DataProcessor(config.data.data_file)
        
        
        sample_data = processor.data.sample(n=min(50000, len(processor.data)), random_state=42)
        processor.data = sample_data
        
        
        features = processor.create_behavioral_features()
        
        print(f"   ‚úÖ –ü—Ä–∏–∑–Ω–∞–∫–∏ —Å–æ–∑–¥–∞–Ω—ã —É—Å–ø–µ—à–Ω–æ")
        print(f"   üìä –ö–æ–ª–∏—á–µ—Å—Ç–≤–æ –∫–ª–∏–µ–Ω—Ç–æ–≤: {len(features):,}")
        print(f"   üî¢ –ö–æ–ª–∏—á–µ—Å—Ç–≤–æ –ø—Ä–∏–∑–Ω–∞–∫–æ–≤: {len(features.columns)}")
        print(f"   üìã –û—Å–Ω–æ–≤–Ω—ã–µ –ø—Ä–∏–∑–Ω–∞–∫–∏: {list(features.columns[:5])}")
        
        
        missing_values = features.isnull().sum().sum()
        print(f"   üîç –ü—Ä–æ–ø—É—â–µ–Ω–Ω—ã–µ –∑–Ω–∞—á–µ–Ω–∏—è: {missing_values}")
        
        return True, features
        
    except Exception as e:
        print(f"‚ùå –û—à–∏–±–∫–∞ —Å–æ–∑–¥–∞–Ω–∏—è –ø—Ä–∏–∑–Ω–∞–∫–æ–≤: {e}")
        return False, None

def test_clustering():
    """–¢–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ –∫–ª–∞—Å—Ç–µ—Ä–∏–∑–∞—Ü–∏–∏"""
    print("\nü§ñ –¢–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ –∫–ª–∞—Å—Ç–µ—Ä–∏–∑–∞—Ü–∏–∏...")
    
    try:
        from config import config
        from data_processor import DataProcessor
        from clustering_models import ClusteringModels
        
        processor = DataProcessor(config.data.data_file)
        
        
        sample_data = processor.data.sample(n=min(10000, len(processor.data)), random_state=42)
        processor.data = sample_data
        
        
        features = processor.create_behavioral_features()
        
        
        scaled_features, clean_indices = processor.prepare_features_for_clustering()
        
        print(f"   ‚úÖ –î–∞–Ω–Ω—ã–µ –ø–æ–¥–≥–æ—Ç–æ–≤–ª–µ–Ω—ã")
        print(f"   üìä –†–∞–∑–º–µ—Ä –≤—ã–±–æ—Ä–∫–∏: {scaled_features.shape}")
        print(f"   üßπ –û—á–∏—â–µ–Ω–æ –æ—Ç –≤—ã–±—Ä–æ—Å–æ–≤: {len(clean_indices)} –∫–ª–∏–µ–Ω—Ç–æ–≤")
        
        
        clustering = ClusteringModels(scaled_features, features.columns.tolist())
        
        
        clustering.fit_kmeans(n_clusters=5)
        
        print(f"   ‚úÖ K-Means –∫–ª–∞—Å—Ç–µ—Ä–∏–∑–∞—Ü–∏—è –≤—ã–ø–æ–ª–Ω–µ–Ω–∞")
        print(f"   üéØ –ö–æ–ª–∏—á–µ—Å—Ç–≤–æ –∫–ª–∞—Å—Ç–µ—Ä–æ–≤: 5")
        
        
        labels = clustering.results['kmeans']['labels']
        unique_labels = np.unique(labels)
        
        print(f"   üìà –ù–∞–π–¥–µ–Ω–æ –∫–ª–∞—Å—Ç–µ—Ä–æ–≤: {len(unique_labels)}")
        print(f"   üìä –†–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ –ø–æ –∫–ª–∞—Å—Ç–µ—Ä–∞–º:")
        
        for label in unique_labels:
            count = np.sum(labels == label)
            percentage = (count / len(labels)) * 100
            print(f"      –ö–ª–∞—Å—Ç–µ—Ä {label}: {count} –∫–ª–∏–µ–Ω—Ç–æ–≤ ({percentage:.1f}%)")
        
        return True, clustering, features, scaled_features, clean_indices
        
    except Exception as e:
        print(f"‚ùå –û—à–∏–±–∫–∞ –∫–ª–∞—Å—Ç–µ—Ä–∏–∑–∞—Ü–∏–∏: {e}")
        return False, None, None, None, None

def test_analysis():
    """–¢–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ –∞–Ω–∞–ª–∏–∑–∞ —Å–µ–≥–º–µ–Ω—Ç–æ–≤"""
    print("\nüìà –¢–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ –∞–Ω–∞–ª–∏–∑–∞ —Å–µ–≥–º–µ–Ω—Ç–æ–≤...")
    
    try:
        
        success, clustering, features, scaled_features, clean_indices = test_clustering()
        
        if not success:
            return False
        
        from segment_analyzer import SegmentAnalyzer
        
        
        analyzer = SegmentAnalyzer(
            client_features=features,
            cluster_labels=clustering.results['kmeans']['labels'],
            scaled_features=scaled_features,
            clean_indices=clean_indices
        )
        
        
        segment_profiles = analyzer.analyze_segments()
        
        print(f"   ‚úÖ –ê–Ω–∞–ª–∏–∑ —Å–µ–≥–º–µ–Ω—Ç–æ–≤ –≤—ã–ø–æ–ª–Ω–µ–Ω")
        print(f"   üéØ –ö–æ–ª–∏—á–µ—Å—Ç–≤–æ —Å–µ–≥–º–µ–Ω—Ç–æ–≤: {len(segment_profiles)}")
        
        
        for cluster_id, profile in segment_profiles.items():
            segment_type = profile['segment_type']
            print(f"      {segment_type['name']}: {profile['percentage']:.1f}% –∫–ª–∏–µ–Ω—Ç–æ–≤")
        
        return True
        
    except Exception as e:
        print(f"‚ùå –û—à–∏–±–∫–∞ –∞–Ω–∞–ª–∏–∑–∞ —Å–µ–≥–º–µ–Ω—Ç–æ–≤: {e}")
        return False

def demo_advanced_analytics():
    """–î–µ–º–æ–Ω—Å—Ç—Ä–∞—Ü–∏—è —Ä–∞—Å—à–∏—Ä–µ–Ω–Ω–æ–π –∞–Ω–∞–ª–∏—Ç–∏–∫–∏"""
    print("\nüî¨ –î–µ–º–æ–Ω—Å—Ç—Ä–∞—Ü–∏—è —Ä–∞—Å—à–∏—Ä–µ–Ω–Ω–æ–π –∞–Ω–∞–ª–∏—Ç–∏–∫–∏...")
    
    try:
        from config import config
        from data_processor import DataProcessor
        from clustering_models import ClusteringModels
        from segment_analyzer import SegmentAnalyzer
        
        
        processor = DataProcessor(config.data.data_file)
        sample_data = processor.data.sample(n=min(5000, len(processor.data)), random_state=42)
        processor.data = sample_data
        
        print(f"   üìä –ó–∞–≥—Ä—É–∂–µ–Ω–∞ –≤—ã–±–æ—Ä–∫–∞: {len(sample_data)} –∑–∞–ø–∏—Å–µ–π")
        
        
        features = processor.create_behavioral_features()
        scaled_features, clean_indices = processor.prepare_features_for_clustering()
        
        
        clustering = ClusteringModels(scaled_features, features.columns.tolist())
        best_result = clustering.fit_kmeans(n_clusters=3)  
        
        
        analyzer = SegmentAnalyzer(
            client_features=features,
            cluster_labels=best_result['labels'],
            scaled_features=scaled_features,
            clean_indices=clean_indices
        )
        
        
        analyzer.analyze_segments()
        analyzer.generate_business_recommendations()
        
        print("\nüî¨ –î–µ–º–æ–Ω—Å—Ç—Ä–∞—Ü–∏—è –Ω–æ–≤—ã—Ö –≤–æ–∑–º–æ–∂–Ω–æ—Å—Ç–µ–π:")
        
        
        print("\nüìä 1. –ê–Ω–∞–ª–∏–∑ —Å—Ç–∞–±–∏–ª—å–Ω–æ—Å—Ç–∏ —Å–µ–≥–º–µ–Ω—Ç–æ–≤:")
        stability = analyzer.analyze_segment_stability()
        for cluster_id, metrics in stability.items():
            print(f"   –°–µ–≥–º–µ–Ω—Ç {cluster_id}: –°—Ç–∞–±–∏–ª—å–Ω–æ—Å—Ç—å {metrics['consistency_score']:.2f}, –†–∏—Å–∫ –æ—Ç—Ç–æ–∫–∞ {metrics['churn_risk']:.1%}")
        
        
        print("\nüí∞ 2. Customer Lifetime Value:")
        clv_data = analyzer.calculate_customer_lifetime_value()
        for cluster_id, clv in clv_data.items():
            print(f"   –°–µ–≥–º–µ–Ω—Ç {cluster_id}: CLV {clv['adjusted_clv']:,.0f} —Ç–µ–Ω–≥–µ, –£—Ä–æ–≤–µ–Ω—å: {clv['value_tier']}")
        
        
        print("\nüõ§Ô∏è 3. –ê–Ω–∞–ª–∏–∑ –∂–∏–∑–Ω–µ–Ω–Ω–æ–≥–æ —Ü–∏–∫–ª–∞:")
        journey = analyzer.analyze_customer_journey()
        for cluster_id, data in journey.items():
            print(f"   –°–µ–≥–º–µ–Ω—Ç {cluster_id}: {data['lifecycle_stage']}, –í–æ–≤–ª–µ—á–µ–Ω–Ω–æ—Å—Ç—å: {data['engagement_level']}")
        
        
        print("\nüìä 4. –°–∏—Å—Ç–µ–º–∞ –º–æ–Ω–∏—Ç–æ—Ä–∏–Ω–≥–∞:")
        monitoring = analyzer.create_monitoring_dashboard_data()
        print(f"   –°–æ–∑–¥–∞–Ω–æ –∞–ª–µ—Ä—Ç–æ–≤: {len(monitoring['alerts'])}")
        for alert in monitoring['alerts'][:2]:  
            print(f"   - {alert['severity']}: {alert['message']}")
        
        
        print("\nüß™ 5. –ü–ª–∞–Ω A/B —Ç–µ—Å—Ç–æ–≤:")
        ab_tests = analyzer.design_ab_test_framework()
        for cluster_id, test_data in ab_tests.items():
            print(f"   –°–µ–≥–º–µ–Ω—Ç {cluster_id}: {len(test_data['test_scenarios'])} —Ç–µ—Å—Ç–æ–≤, "
                  f"–î–ª–∏—Ç–µ–ª—å–Ω–æ—Å—Ç—å: {test_data['test_duration_weeks']} –Ω–µ–¥–µ–ª—å")
        
        
        print("\nüìã 6. –ê–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏–µ –æ—Ç—á–µ—Ç—ã:")
        report = analyzer.generate_executive_report()
        presentation = analyzer.create_presentation_slides()
        print(f"   –ò—Å–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω—ã–π –æ—Ç—á–µ—Ç: {len(report)} —Å–∏–º–≤–æ–ª–æ–≤")
        print(f"   –°–ª–∞–π–¥–æ–≤ –ø—Ä–µ–∑–µ–Ω—Ç–∞—Ü–∏–∏: {len(presentation)} —Ä–∞–∑–¥–µ–ª–æ–≤")
        
        print("\n‚úÖ –î–µ–º–æ–Ω—Å—Ç—Ä–∞—Ü–∏—è —Ä–∞—Å—à–∏—Ä–µ–Ω–Ω–æ–π –∞–Ω–∞–ª–∏—Ç–∏–∫–∏ –∑–∞–≤–µ—Ä—à–µ–Ω–∞!")
        print("üìÅ –í—Å–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã —Å–æ—Ö—Ä–∞–Ω–µ–Ω—ã –≤ –ø–∞–ø–∫–µ 'results/'")
        
        return True
        
    except Exception as e:
        print(f"‚ùå –û—à–∏–±–∫–∞ –≤ –¥–µ–º–æ–Ω—Å—Ç—Ä–∞—Ü–∏–∏ —Ä–∞—Å—à–∏—Ä–µ–Ω–Ω–æ–π –∞–Ω–∞–ª–∏—Ç–∏–∫–∏: {e}")
        return False

def run_demo():
    """–ó–∞–ø—É—Å–∫ –ø–æ–ª–Ω–æ–π –¥–µ–º–æ–Ω—Å—Ç—Ä–∞—Ü–∏–∏"""
    print("="*60)
    print("üöÄ –î–ï–ú–û–ù–°–¢–†–ê–¶–ò–Ø –°–ò–°–¢–ï–ú–´ –°–ï–ì–ú–ï–ù–¢–ê–¶–ò–ò –ö–õ–ò–ï–ù–¢–û–í")
    print("="*60)
    print(f"üìÖ –í—Ä–µ–º—è –∑–∞–ø—É—Å–∫–∞: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}")
    
    
    tests = [
        ("–ò–º–ø–æ—Ä—Ç –º–æ–¥—É–ª–µ–π", test_imports),
        ("–ö–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—è", test_config),
        ("–ó–∞–≥—Ä—É–∑–∫–∞ –¥–∞–Ω–Ω—ã—Ö", test_data_loading),
        ("–°–æ–∑–¥–∞–Ω–∏–µ –ø—Ä–∏–∑–Ω–∞–∫–æ–≤", lambda: test_feature_creation()[0]),
        ("–ö–ª–∞—Å—Ç–µ—Ä–∏–∑–∞—Ü–∏—è", lambda: test_clustering()[0]),
        ("–ê–Ω–∞–ª–∏–∑ —Å–µ–≥–º–µ–Ω—Ç–æ–≤", test_analysis),
        ("–†–∞—Å—à–∏—Ä–µ–Ω–Ω–∞—è –∞–Ω–∞–ª–∏—Ç–∏–∫–∞", demo_advanced_analytics)
    ]
    
    results = []
    
    for test_name, test_func in tests:
        print(f"\n{'='*20} {test_name} {'='*20}")
        
        try:
            result = test_func()
            results.append((test_name, result))
            
            if result:
                print(f"‚úÖ {test_name} - –£–°–ü–ï–®–ù–û")
            else:
                print(f"‚ùå {test_name} - –û–®–ò–ë–ö–ê")
                break  
                
        except Exception as e:
            print(f"‚ùå {test_name} - –ö–†–ò–¢–ò–ß–ï–°–ö–ê–Ø –û–®–ò–ë–ö–ê: {e}")
            results.append((test_name, False))
            break
    
    
    print("\n" + "="*60)
    print("üìã –ò–¢–û–ì–û–í–´–ô –û–¢–ß–ï–¢ –î–ï–ú–û–ù–°–¢–†–ê–¶–ò–ò")
    print("="*60)
    
    passed = sum(1 for _, result in results if result)
    total = len(results)
    
    print(f"‚úÖ –ü—Ä–æ–π–¥–µ–Ω–æ —Ç–µ—Å—Ç–æ–≤: {passed}/{total}")
    print(f"üìä –ü—Ä–æ—Ü–µ–Ω—Ç —É—Å–ø–µ—Ö–∞: {(passed/total)*100:.1f}%")
    
    print("\nüìã –î–µ—Ç–∞–ª—å–Ω—ã–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã:")
    for test_name, result in results:
        status = "‚úÖ –£–°–ü–ï–®–ù–û" if result else "‚ùå –û–®–ò–ë–ö–ê"
        print(f"   {test_name}: {status}")
    
    if passed == total:
        print("\nüéâ –í–°–ï –¢–ï–°–¢–´ –ü–†–û–ô–î–ï–ù–´ –£–°–ü–ï–®–ù–û!")
        print("üöÄ –°–∏—Å—Ç–µ–º–∞ –≥–æ—Ç–æ–≤–∞ –∫ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—é!")
        print("\nüí° –î–ª—è –∑–∞–ø—É—Å–∫–∞ –ø–æ–ª–Ω–æ–≥–æ –∞–Ω–∞–ª–∏–∑–∞ –∏—Å–ø–æ–ª—å–∑—É–π—Ç–µ:")
        print("   python main.py")
        print("\nüí° –î–ª—è –±—ã—Å—Ç—Ä–æ–≥–æ –∞–Ω–∞–ª–∏–∑–∞ –∏—Å–ø–æ–ª—å–∑—É–π—Ç–µ:")
        print("   python main.py --quick")
    else:
        print("\n‚ö†Ô∏è –û–ë–ù–ê–†–£–ñ–ï–ù–´ –ü–†–û–ë–õ–ï–ú–´!")
        print("üîß –†–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–∏ –ø–æ —É—Å—Ç—Ä–∞–Ω–µ–Ω–∏—é:")
        print("   1. –ü—Ä–æ–≤–µ—Ä—å—Ç–µ —É—Å—Ç–∞–Ω–æ–≤–∫—É –≤—Å–µ—Ö –∑–∞–≤–∏—Å–∏–º–æ—Å—Ç–µ–π: pip install -r requirements.txt")
        print("   2. –£–±–µ–¥–∏—Ç–µ—Å—å –≤ –Ω–∞–ª–∏—á–∏–∏ —Ñ–∞–π–ª–∞ –¥–∞–Ω–Ω—ã—Ö: DECENTRATHON_3.0.parquet")
        print("   3. –ü—Ä–æ–≤–µ—Ä—å—Ç–µ –ø—Ä–∞–≤–∞ –¥–æ—Å—Ç—É–ø–∞ –∫ —Ñ–∞–π–ª–∞–º –∏ –ø–∞–ø–∫–∞–º")
    
    print("="*60)

if __name__ == "__main__":
    run_demo() 