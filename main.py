"""
Ð“Ð»Ð°Ð²Ð½Ñ‹Ð¹ Ð¼Ð¾Ð´ÑƒÐ»ÑŒ Ð´Ð»Ñ Ð°Ð½Ð°Ð»Ð¸Ð·Ð° ÑÐµÐ³Ð¼ÐµÐ½Ñ‚Ð°Ñ†Ð¸Ð¸ Ð±Ð°Ð½ÐºÐ¾Ð²ÑÐºÐ¸Ñ… ÐºÐ»Ð¸ÐµÐ½Ñ‚Ð¾Ð²
ÐŸÑ€Ð¾ÐµÐºÑ‚: Ð¡ÐµÐ³Ð¼ÐµÐ½Ñ‚Ð°Ñ†Ð¸Ñ ÐºÐ»Ð¸ÐµÐ½Ñ‚Ð¾Ð² Ð½Ð° Ð¾ÑÐ½Ð¾Ð²Ðµ Ð¿Ð¾Ð²ÐµÐ´ÐµÐ½Ñ‡ÐµÑÐºÐ¸Ñ… Ñ…Ð°Ñ€Ð°ÐºÑ‚ÐµÑ€Ð¸ÑÑ‚Ð¸Ðº
"""

import warnings
warnings.filterwarnings('ignore')

import matplotlib
matplotlib.use('Agg')  # Ð˜ÑÐ¿Ð¾Ð»ÑŒÐ·ÑƒÐµÐ¼ backend Ð±ÐµÐ· GUI

import pandas as pd
import numpy as np
from datetime import datetime
import os


from config import config
from data_processor import DataProcessor
from clustering_models import ClusteringModels
from segment_analyzer import SegmentAnalyzer

def print_project_header():
    """ÐŸÐµÑ‡Ð°Ñ‚ÑŒ Ð·Ð°Ð³Ð¾Ð»Ð¾Ð²ÐºÐ° Ð¿Ñ€Ð¾ÐµÐºÑ‚Ð°"""
    print("="*80)
    print("ðŸ¦ ÐÐÐÐ›Ð˜Ð— Ð¡Ð•Ð“ÐœÐ•ÐÐ¢ÐÐ¦Ð˜Ð˜ Ð‘ÐÐÐšÐžÐ’Ð¡ÐšÐ˜Ð¥ ÐšÐ›Ð˜Ð•ÐÐ¢ÐžÐ’")
    print("="*80)
    print("ðŸ“Š ÐŸÑ€Ð¾ÐµÐºÑ‚: Ð¡ÐµÐ³Ð¼ÐµÐ½Ñ‚Ð°Ñ†Ð¸Ñ ÐºÐ»Ð¸ÐµÐ½Ñ‚Ð¾Ð² Ð½Ð° Ð¾ÑÐ½Ð¾Ð²Ðµ Ð¿Ð¾Ð²ÐµÐ´ÐµÐ½Ñ‡ÐµÑÐºÐ¸Ñ… Ñ…Ð°Ñ€Ð°ÐºÑ‚ÐµÑ€Ð¸ÑÑ‚Ð¸Ðº")
    print("ðŸŽ¯ Ð¦ÐµÐ»ÑŒ: Ð’Ñ‹ÑÐ²Ð»ÐµÐ½Ð¸Ðµ Ð³Ñ€ÑƒÐ¿Ð¿ ÐºÐ»Ð¸ÐµÐ½Ñ‚Ð¾Ð² Ñ Ð¿Ð¾Ñ…Ð¾Ð¶Ð¸Ð¼ Ð¿Ð¾Ð²ÐµÐ´ÐµÐ½Ð¸ÐµÐ¼ Ð´Ð»Ñ Ð¿ÐµÑ€ÑÐ¾Ð½Ð°Ð»Ð¸Ð·Ð°Ñ†Ð¸Ð¸")
    print("ðŸ”¬ ÐŸÐ¾Ð´Ñ…Ð¾Ð´: ÐœÐ°ÑˆÐ¸Ð½Ð½Ð¾Ðµ Ð¾Ð±ÑƒÑ‡ÐµÐ½Ð¸Ðµ Ð±ÐµÐ· ÑƒÑ‡Ð¸Ñ‚ÐµÐ»Ñ (ÐºÐ»Ð°ÑÑ‚ÐµÑ€Ð¸Ð·Ð°Ñ†Ð¸Ñ)")
    print("ðŸ“… Ð”Ð°Ñ‚Ð° Ð·Ð°Ð¿ÑƒÑÐºÐ°:", datetime.now().strftime("%Y-%m-%d %H:%M:%S"))
    print("="*80)

def main():
    """ÐžÑÐ½Ð¾Ð²Ð½Ð°Ñ Ñ„ÑƒÐ½ÐºÑ†Ð¸Ñ Ð´Ð»Ñ Ð²Ñ‹Ð¿Ð¾Ð»Ð½ÐµÐ½Ð¸Ñ Ð¿Ð¾Ð»Ð½Ð¾Ð³Ð¾ Ð°Ð½Ð°Ð»Ð¸Ð·Ð°"""
    
    
    print_project_header()
    
    try:
        
        
        
        print("\nðŸ” Ð­Ð¢ÐÐŸ 1: Ð—ÐÐ“Ð Ð£Ð—ÐšÐ Ð˜ Ð˜Ð¡Ð¡Ð›Ð•Ð”ÐžÐ’ÐÐÐ˜Ð• Ð”ÐÐÐÐ«Ð¥")
        print("-" * 50)
        
        
        data_processor = DataProcessor(config.data.data_file)
        
        
        data_processor.explore_data()
        
        
        
        
        print("\nðŸ› ï¸ Ð­Ð¢ÐÐŸ 2: Ð¡ÐžÐ—Ð”ÐÐÐ˜Ð• ÐŸÐžÐ’Ð•Ð”Ð•ÐÐ§Ð•Ð¡ÐšÐ˜Ð¥ ÐŸÐ Ð˜Ð—ÐÐÐšÐžÐ’")
        print("-" * 50)
        
        
        client_features = data_processor.create_behavioral_features()
        
        print(f"âœ… Ð¡Ð¾Ð·Ð´Ð°Ð½Ð¾ Ð¿Ñ€Ð¸Ð·Ð½Ð°ÐºÐ¾Ð²: {len(client_features.columns)}")
        print(f"âœ… ÐšÐ¾Ð»Ð¸Ñ‡ÐµÑÑ‚Ð²Ð¾ ÐºÐ»Ð¸ÐµÐ½Ñ‚Ð¾Ð²: {len(client_features):,}")
        
        
        
        
        print("\nâš™ï¸ Ð­Ð¢ÐÐŸ 3: ÐŸÐžÐ”Ð“ÐžÐ¢ÐžÐ’ÐšÐ Ð”ÐÐÐÐ«Ð¥ Ð”Ð›Ð¯ ÐšÐ›ÐÐ¡Ð¢Ð•Ð Ð˜Ð—ÐÐ¦Ð˜Ð˜")
        print("-" * 50)
        
        
        scaled_features, clean_indices = data_processor.prepare_features_for_clustering()
        
        print(f"âœ… Ð”Ð°Ð½Ð½Ñ‹Ðµ Ð¾Ñ‡Ð¸Ñ‰ÐµÐ½Ñ‹ Ð¾Ñ‚ Ð²Ñ‹Ð±Ñ€Ð¾ÑÐ¾Ð²: {len(clean_indices):,} ÐºÐ»Ð¸ÐµÐ½Ñ‚Ð¾Ð²")
        print(f"âœ… ÐŸÑ€Ð¸Ð·Ð½Ð°ÐºÐ¸ Ð¼Ð°ÑÑˆÑ‚Ð°Ð±Ð¸Ñ€Ð¾Ð²Ð°Ð½Ñ‹: {scaled_features.shape[1]} Ð¿Ñ€Ð¸Ð·Ð½Ð°ÐºÐ¾Ð²")
        
        
        feature_importance = data_processor.get_feature_importance_analysis()
        print("\nðŸ“Š Ð¢Ð¾Ð¿-10 Ð½Ð°Ð¸Ð±Ð¾Ð»ÐµÐµ Ð²Ð°Ñ€Ð¸Ð°Ñ‚Ð¸Ð²Ð½Ñ‹Ñ… Ð¿Ñ€Ð¸Ð·Ð½Ð°ÐºÐ¾Ð²:")
        top_features = feature_importance.nlargest(10, 'coefficient_of_variation')
        for _, row in top_features.iterrows():
            print(f"   â€¢ {row['feature']}: {row['coefficient_of_variation']:.3f}")
        
        
        data_processor.save_feature_analysis()
        
        
        
        
        print("\nðŸ¤– Ð­Ð¢ÐÐŸ 4: ÐšÐ›ÐÐ¡Ð¢Ð•Ð Ð˜Ð—ÐÐ¦Ð˜Ð¯ ÐšÐ›Ð˜Ð•ÐÐ¢ÐžÐ’")
        print("-" * 50)
        
        
        clustering_models = ClusteringModels(scaled_features, client_features.columns.tolist())
        
        
        print("\nðŸ” ÐŸÐ¾Ð¸ÑÐº Ð¾Ð¿Ñ‚Ð¸Ð¼Ð°Ð»ÑŒÐ½Ð¾Ð³Ð¾ ÐºÐ¾Ð»Ð¸Ñ‡ÐµÑÑ‚Ð²Ð° ÐºÐ»Ð°ÑÑ‚ÐµÑ€Ð¾Ð²...")
        optimal_k = clustering_models.find_optimal_clusters_kmeans()
        
        
        print("\nðŸŽ¯ ÐžÐ±ÑƒÑ‡ÐµÐ½Ð¸Ðµ Ð¼Ð¾Ð´ÐµÐ»ÐµÐ¹ ÐºÐ»Ð°ÑÑ‚ÐµÑ€Ð¸Ð·Ð°Ñ†Ð¸Ð¸...")
        
        
        clustering_models.fit_kmeans(n_clusters=optimal_k)
        
        
        clustering_models.fit_dbscan()
        
        
        clustering_models.fit_gaussian_mixture(n_components=optimal_k)
        
        
        print("\nðŸ“Š Ð¡Ñ€Ð°Ð²Ð½ÐµÐ½Ð¸Ðµ Ð¼Ð¾Ð´ÐµÐ»ÐµÐ¹ ÐºÐ»Ð°ÑÑ‚ÐµÑ€Ð¸Ð·Ð°Ñ†Ð¸Ð¸:")
        comparison_results = clustering_models.compare_models()
        print(comparison_results)
        
        
        best_model_name = comparison_results.loc[comparison_results['Ð¡Ð¸Ð»ÑƒÑÑ‚Ð½Ñ‹Ð¹ ÐºÐ¾ÑÑ„Ñ„Ð¸Ñ†Ð¸ÐµÐ½Ñ‚'].idxmax(), 'ÐœÐ¾Ð´ÐµÐ»ÑŒ']
        
        
        model_name_mapping = {
            'Kmeans': 'kmeans',
            'Dbscan': 'dbscan', 
            'Gaussian Mixture': 'gaussian_mixture',
            'Hierarchical': 'hierarchical'
        }
        best_model_key = model_name_mapping.get(best_model_name, best_model_name.lower())
        best_labels = clustering_models.results[best_model_key]['labels']
        
        print(f"\nðŸ† Ð›ÑƒÑ‡ÑˆÐ°Ñ Ð¼Ð¾Ð´ÐµÐ»ÑŒ: {best_model_name}")
        
        
        clustering_models.explain_model_choice(best_model_key)
        
        
        
        
        print("\nðŸ“ˆ Ð­Ð¢ÐÐŸ 5: ÐÐÐÐ›Ð˜Ð— Ð¡Ð•Ð“ÐœÐ•ÐÐ¢ÐžÐ’")
        print("-" * 50)
        
        
        segment_analyzer = SegmentAnalyzer(
            client_features=client_features,
            cluster_labels=best_labels,
            scaled_features=scaled_features,
            clean_indices=clean_indices
        )
        
        
        segment_profiles = segment_analyzer.analyze_segments()
        
        
        
        
        print("\nðŸŽ¨ Ð­Ð¢ÐÐŸ 6: Ð¡ÐžÐ—Ð”ÐÐÐ˜Ð• Ð’Ð˜Ð—Ð£ÐÐ›Ð˜Ð—ÐÐ¦Ð˜Ð™")
        print("-" * 50)
        
        
        segment_analyzer.create_comprehensive_visualizations()
        
        
        
        
        print("\nðŸ’¼ Ð­Ð¢ÐÐŸ 7: Ð“Ð•ÐÐ•Ð ÐÐ¦Ð˜Ð¯ Ð‘Ð˜Ð—ÐÐ•Ð¡-Ð Ð•ÐšÐžÐœÐ•ÐÐ”ÐÐ¦Ð˜Ð™")
        print("-" * 50)
        
        
        business_recommendations = segment_analyzer.generate_business_recommendations()
        
        
        
        
        print("\nðŸ’¾ Ð­Ð¢ÐÐŸ 8: Ð¡ÐžÐ¥Ð ÐÐÐ•ÐÐ˜Ð• Ð Ð•Ð—Ð£Ð›Ð¬Ð¢ÐÐ¢ÐžÐ’")
        print("-" * 50)
        
        
        segment_analyzer.save_detailed_analysis()
        
        
        
        
        print("\nðŸ“‹ Ð­Ð¢ÐÐŸ 9: Ð˜Ð¢ÐžÐ“ÐžÐ’ÐžÐ• Ð Ð•Ð—Ð®ÐœÐ•")
        print("-" * 50)
        
        
        segment_analyzer.print_executive_summary()
        
        
        
        
        print("\n" + "="*80)
        print("ðŸŽ‰ ÐÐÐÐ›Ð˜Ð— Ð£Ð¡ÐŸÐ•Ð¨ÐÐž Ð—ÐÐ’Ð•Ð Ð¨Ð•Ð!")
        print("="*80)
        
        print(f"ðŸ“ Ð’ÑÐµ Ñ€ÐµÐ·ÑƒÐ»ÑŒÑ‚Ð°Ñ‚Ñ‹ ÑÐ¾Ñ…Ñ€Ð°Ð½ÐµÐ½Ñ‹ Ð² Ð¿Ð°Ð¿ÐºÐµ: {config.data.output_dir}")
        print("\nðŸ“Š Ð¡Ð¾Ð·Ð´Ð°Ð½Ð½Ñ‹Ðµ Ñ„Ð°Ð¹Ð»Ñ‹:")
        
        
        output_files = [
            "client_segments.csv - Ð ÐµÐ·ÑƒÐ»ÑŒÑ‚Ð°Ñ‚Ñ‹ ÑÐµÐ³Ð¼ÐµÐ½Ñ‚Ð°Ñ†Ð¸Ð¸ ÐºÐ»Ð¸ÐµÐ½Ñ‚Ð¾Ð²",
            "segment_summary.csv - Ð¡Ð²Ð¾Ð´Ð½Ð°Ñ ÑÑ‚Ð°Ñ‚Ð¸ÑÑ‚Ð¸ÐºÐ° Ð¿Ð¾ ÑÐµÐ³Ð¼ÐµÐ½Ñ‚Ð°Ð¼", 
            "segment_profiles.json - Ð”ÐµÑ‚Ð°Ð»ÑŒÐ½Ñ‹Ðµ Ð¿Ñ€Ð¾Ñ„Ð¸Ð»Ð¸ ÑÐµÐ³Ð¼ÐµÐ½Ñ‚Ð¾Ð²",
            "business_recommendations.json - Ð‘Ð¸Ð·Ð½ÐµÑ-Ñ€ÐµÐºÐ¾Ð¼ÐµÐ½Ð´Ð°Ñ†Ð¸Ð¸",
            "feature_analysis.csv - ÐÐ½Ð°Ð»Ð¸Ð· Ð²Ð°Ð¶Ð½Ð¾ÑÑ‚Ð¸ Ð¿Ñ€Ð¸Ð·Ð½Ð°ÐºÐ¾Ð²",
            "segment_dashboard.html - Ð˜Ð½Ñ‚ÐµÑ€Ð°ÐºÑ‚Ð¸Ð²Ð½Ñ‹Ð¹ Ð´Ð°ÑˆÐ±Ð¾Ñ€Ð´",
            "segment_analysis_static.png - Ð¡Ñ‚Ð°Ñ‚Ð¸Ñ‡Ð½Ñ‹Ðµ Ð³Ñ€Ð°Ñ„Ð¸ÐºÐ¸",
            "pca_visualization.png - PCA Ð²Ð¸Ð·ÑƒÐ°Ð»Ð¸Ð·Ð°Ñ†Ð¸Ñ",
            "segment_heatmap.png - Ð¢ÐµÐ¿Ð»Ð¾Ð²Ð°Ñ ÐºÐ°Ñ€Ñ‚Ð° Ñ…Ð°Ñ€Ð°ÐºÑ‚ÐµÑ€Ð¸ÑÑ‚Ð¸Ðº",
            "cluster_optimization.png - Ð“Ñ€Ð°Ñ„Ð¸Ðº Ð¾Ð¿Ñ‚Ð¸Ð¼Ð¸Ð·Ð°Ñ†Ð¸Ð¸ ÐºÐ»Ð°ÑÑ‚ÐµÑ€Ð¾Ð²"
        ]
        
        for file_desc in output_files:
            print(f"   â€¢ {file_desc}")
        
        print("\nðŸ’¡ Ð ÐµÐºÐ¾Ð¼ÐµÐ½Ð´Ð°Ñ†Ð¸Ð¸ Ð¿Ð¾ Ð¸ÑÐ¿Ð¾Ð»ÑŒÐ·Ð¾Ð²Ð°Ð½Ð¸ÑŽ Ñ€ÐµÐ·ÑƒÐ»ÑŒÑ‚Ð°Ñ‚Ð¾Ð²:")
        print("   1. Ð˜Ð·ÑƒÑ‡Ð¸Ñ‚Ðµ Ð¸Ð½Ñ‚ÐµÑ€Ð°ÐºÑ‚Ð¸Ð²Ð½Ñ‹Ð¹ Ð´Ð°ÑˆÐ±Ð¾Ñ€Ð´ Ð´Ð»Ñ Ð¾Ð±Ñ‰ÐµÐ³Ð¾ Ð¿Ð¾Ð½Ð¸Ð¼Ð°Ð½Ð¸Ñ ÑÐµÐ³Ð¼ÐµÐ½Ñ‚Ð¾Ð²")
        print("   2. Ð˜ÑÐ¿Ð¾Ð»ÑŒÐ·ÑƒÐ¹Ñ‚Ðµ Ð±Ð¸Ð·Ð½ÐµÑ-Ñ€ÐµÐºÐ¾Ð¼ÐµÐ½Ð´Ð°Ñ†Ð¸Ð¸ Ð´Ð»Ñ Ð¿Ð»Ð°Ð½Ð¸Ñ€Ð¾Ð²Ð°Ð½Ð¸Ñ Ð¼Ð°Ñ€ÐºÐµÑ‚Ð¸Ð½Ð³Ð¾Ð²Ñ‹Ñ… ÐºÐ°Ð¼Ð¿Ð°Ð½Ð¸Ð¹")
        print("   3. Ð ÐµÐ³ÑƒÐ»ÑÑ€Ð½Ð¾ Ð¾Ð±Ð½Ð¾Ð²Ð»ÑÐ¹Ñ‚Ðµ ÑÐµÐ³Ð¼ÐµÐ½Ñ‚Ð°Ñ†Ð¸ÑŽ Ñ Ð½Ð¾Ð²Ñ‹Ð¼Ð¸ Ð´Ð°Ð½Ð½Ñ‹Ð¼Ð¸")
        print("   4. ÐœÐ¾Ð½Ð¸Ñ‚Ð¾Ñ€ÑŒÑ‚Ðµ KPI Ð´Ð»Ñ Ð¾Ñ†ÐµÐ½ÐºÐ¸ ÑÑ„Ñ„ÐµÐºÑ‚Ð¸Ð²Ð½Ð¾ÑÑ‚Ð¸ ÑÑ‚Ñ€Ð°Ñ‚ÐµÐ³Ð¸Ð¹")
        
        print("\nðŸš€ Ð¡Ð»ÐµÐ´ÑƒÑŽÑ‰Ð¸Ðµ ÑˆÐ°Ð³Ð¸:")
        print("   â€¢ Ð’Ð½ÐµÐ´Ñ€ÐµÐ½Ð¸Ðµ Ð¿ÐµÑ€ÑÐ¾Ð½Ð°Ð»Ð¸Ð·Ð¸Ñ€Ð¾Ð²Ð°Ð½Ð½Ñ‹Ñ… Ð¿Ñ€ÐµÐ´Ð»Ð¾Ð¶ÐµÐ½Ð¸Ð¹")
        print("   â€¢ A/B Ñ‚ÐµÑÑ‚Ð¸Ñ€Ð¾Ð²Ð°Ð½Ð¸Ðµ ÑÑ‚Ñ€Ð°Ñ‚ÐµÐ³Ð¸Ð¹ Ð´Ð»Ñ ÐºÐ°Ð¶Ð´Ð¾Ð³Ð¾ ÑÐµÐ³Ð¼ÐµÐ½Ñ‚Ð°")
        print("   â€¢ ÐÐ²Ñ‚Ð¾Ð¼Ð°Ñ‚Ð¸Ð·Ð°Ñ†Ð¸Ñ Ð¿Ñ€Ð¾Ñ†ÐµÑÑÐ° ÑÐµÐ³Ð¼ÐµÐ½Ñ‚Ð°Ñ†Ð¸Ð¸")
        print("   â€¢ Ð˜Ð½Ñ‚ÐµÐ³Ñ€Ð°Ñ†Ð¸Ñ Ñ CRM ÑÐ¸ÑÑ‚ÐµÐ¼Ð¾Ð¹ Ð±Ð°Ð½ÐºÐ°")
        
        return True
        
    except Exception as e:
        print(f"\nâŒ ÐžÐ¨Ð˜Ð‘ÐšÐ ÐŸÐ Ð˜ Ð’Ð«ÐŸÐžÐ›ÐÐ•ÐÐ˜Ð˜ ÐÐÐÐ›Ð˜Ð—Ð:")
        print(f"   {str(e)}")
        print("\nðŸ”§ Ð ÐµÐºÐ¾Ð¼ÐµÐ½Ð´Ð°Ñ†Ð¸Ð¸ Ð¿Ð¾ ÑƒÑÑ‚Ñ€Ð°Ð½ÐµÐ½Ð¸ÑŽ:")
        print("   1. ÐŸÑ€Ð¾Ð²ÐµÑ€ÑŒÑ‚Ðµ Ð½Ð°Ð»Ð¸Ñ‡Ð¸Ðµ Ñ„Ð°Ð¹Ð»Ð° Ð´Ð°Ð½Ð½Ñ‹Ñ…")
        print("   2. Ð£Ð±ÐµÐ´Ð¸Ñ‚ÐµÑÑŒ Ð² ÐºÐ¾Ñ€Ñ€ÐµÐºÑ‚Ð½Ð¾ÑÑ‚Ð¸ Ð¿ÑƒÑ‚ÐµÐ¹")
        print("   3. ÐŸÑ€Ð¾Ð²ÐµÑ€ÑŒÑ‚Ðµ ÑƒÑÑ‚Ð°Ð½Ð¾Ð²ÐºÑƒ Ð²ÑÐµÑ… Ð·Ð°Ð²Ð¸ÑÐ¸Ð¼Ð¾ÑÑ‚ÐµÐ¹")
        return False

def run_quick_analysis():
    """Ð‘Ñ‹ÑÑ‚Ñ€Ñ‹Ð¹ Ð°Ð½Ð°Ð»Ð¸Ð· Ð´Ð»Ñ Ð´ÐµÐ¼Ð¾Ð½ÑÑ‚Ñ€Ð°Ñ†Ð¸Ð¸"""
    print("\nâš¡ Ð Ð•Ð–Ð˜Ðœ Ð‘Ð«Ð¡Ð¢Ð ÐžÐ“Ðž ÐÐÐÐ›Ð˜Ð—Ð")
    print("-" * 30)
    
    try:
        
        data_processor = DataProcessor(config.data.data_file)
        
        
        client_features = data_processor.create_behavioral_features()
        
        
        sample_size = min(10000, len(client_features))
        sample_features = client_features.sample(n=sample_size, random_state=42)
        
        print(f"ðŸ“Š ÐÐ½Ð°Ð»Ð¸Ð·Ð¸Ñ€ÑƒÐµÐ¼ Ð²Ñ‹Ð±Ð¾Ñ€ÐºÑƒ: {sample_size:,} ÐºÐ»Ð¸ÐµÐ½Ñ‚Ð¾Ð²")
        
        
        scaled_features, clean_indices = data_processor.prepare_features_for_clustering()
        
        
        scaled_sample = scaled_features[:sample_size]
        clean_sample = clean_indices[:sample_size]
        
        
        clustering_models = ClusteringModels(scaled_sample, sample_features.columns.tolist())
        clustering_models.fit_kmeans(n_clusters=5)  
        
        
        segment_analyzer = SegmentAnalyzer(
            client_features=sample_features,
            cluster_labels=clustering_models.results['kmeans']['labels'],
            scaled_features=scaled_sample,
            clean_indices=clean_sample
        )
        
        
        segment_analyzer.analyze_segments()
        
        
        segment_analyzer.print_executive_summary()
        
        print("\nâœ… Ð‘Ñ‹ÑÑ‚Ñ€Ñ‹Ð¹ Ð°Ð½Ð°Ð»Ð¸Ð· Ð·Ð°Ð²ÐµÑ€ÑˆÐµÐ½!")
        
    except Exception as e:
        print(f"âŒ ÐžÑˆÐ¸Ð±ÐºÐ° Ð² Ð±Ñ‹ÑÑ‚Ñ€Ð¾Ð¼ Ð°Ð½Ð°Ð»Ð¸Ð·Ðµ: {str(e)}")

if __name__ == "__main__":
    import sys
    
    
    if len(sys.argv) > 1 and sys.argv[1] == "--quick":
        run_quick_analysis()
    else:
        main() 