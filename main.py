"""
–ì–ª–∞–≤–Ω—ã–π –º–æ–¥—É–ª—å –¥–ª—è –∞–Ω–∞–ª–∏–∑–∞ —Å–µ–≥–º–µ–Ω—Ç–∞—Ü–∏–∏ –±–∞–Ω–∫–æ–≤—Å–∫–∏—Ö –∫–ª–∏–µ–Ω—Ç–æ–≤
–ü—Ä–æ–µ–∫—Ç: –°–µ–≥–º–µ–Ω—Ç–∞—Ü–∏—è –∫–ª–∏–µ–Ω—Ç–æ–≤ –Ω–∞ –æ—Å–Ω–æ–≤–µ –ø–æ–≤–µ–¥–µ–Ω—á–µ—Å–∫–∏—Ö —Ö–∞—Ä–∞–∫—Ç–µ—Ä–∏—Å—Ç–∏–∫
"""

import warnings
warnings.filterwarnings('ignore')

import matplotlib
matplotlib.use('Agg')  # –ò—Å–ø–æ–ª—å–∑—É–µ–º backend –±–µ–∑ GUI

import pandas as pd
import numpy as np
from datetime import datetime
import os


from config import config
from data_processor import DataProcessor
from clustering_models import ClusteringModels
from segment_analyzer import SegmentAnalyzer

def print_project_header():
    """–ü–µ—á–∞—Ç—å –∑–∞–≥–æ–ª–æ–≤–∫–∞ –ø—Ä–æ–µ–∫—Ç–∞"""
    print("="*80)
    print("üè¶ –ê–ù–ê–õ–ò–ó –°–ï–ì–ú–ï–ù–¢–ê–¶–ò–ò –ë–ê–ù–ö–û–í–°–ö–ò–• –ö–õ–ò–ï–ù–¢–û–í")
    print("="*80)
    print("üìä –ü—Ä–æ–µ–∫—Ç: –°–µ–≥–º–µ–Ω—Ç–∞—Ü–∏—è –∫–ª–∏–µ–Ω—Ç–æ–≤ –Ω–∞ –æ—Å–Ω–æ–≤–µ –ø–æ–≤–µ–¥–µ–Ω—á–µ—Å–∫–∏—Ö —Ö–∞—Ä–∞–∫—Ç–µ—Ä–∏—Å—Ç–∏–∫")
    print("üéØ –¶–µ–ª—å: –í—ã—è–≤–ª–µ–Ω–∏–µ –≥—Ä—É–ø–ø –∫–ª–∏–µ–Ω—Ç–æ–≤ —Å –ø–æ—Ö–æ–∂–∏–º –ø–æ–≤–µ–¥–µ–Ω–∏–µ–º –¥–ª—è –ø–µ—Ä—Å–æ–Ω–∞–ª–∏–∑–∞—Ü–∏–∏")
    print("üî¨ –ü–æ–¥—Ö–æ–¥: –ú–∞—à–∏–Ω–Ω–æ–µ –æ–±—É—á–µ–Ω–∏–µ –±–µ–∑ —É—á–∏—Ç–µ–ª—è (–∫–ª–∞—Å—Ç–µ—Ä–∏–∑–∞—Ü–∏—è)")
    print("üìÖ –î–∞—Ç–∞ –∑–∞–ø—É—Å–∫–∞:", datetime.now().strftime("%Y-%m-%d %H:%M:%S"))
    print("="*80)

def main():
    """–û—Å–Ω–æ–≤–Ω–∞—è —Ñ—É–Ω–∫—Ü–∏—è –¥–ª—è –≤—ã–ø–æ–ª–Ω–µ–Ω–∏—è –ø–æ–ª–Ω–æ–≥–æ –∞–Ω–∞–ª–∏–∑–∞"""
    
    
    print_project_header()
    
    try:
        
        
        
        print("\nüîç –≠–¢–ê–ü 1: –ó–ê–ì–†–£–ó–ö–ê –ò –ò–°–°–õ–ï–î–û–í–ê–ù–ò–ï –î–ê–ù–ù–´–•")
        print("-" * 50)
        
        
        data_processor = DataProcessor(config.data.data_file)
        
        
        data_processor.explore_data()
        
        
        
        
        print("\nüõ†Ô∏è –≠–¢–ê–ü 2: –°–û–ó–î–ê–ù–ò–ï –ü–û–í–ï–î–ï–ù–ß–ï–°–ö–ò–• –ü–†–ò–ó–ù–ê–ö–û–í")
        print("-" * 50)
        
        
        client_features = data_processor.create_behavioral_features()
        
        print(f"‚úÖ –°–æ–∑–¥–∞–Ω–æ –ø—Ä–∏–∑–Ω–∞–∫–æ–≤: {len(client_features.columns)}")
        print(f"‚úÖ –ö–æ–ª–∏—á–µ—Å—Ç–≤–æ –∫–ª–∏–µ–Ω—Ç–æ–≤: {len(client_features):,}")
        
        
        
        
        print("\n‚öôÔ∏è –≠–¢–ê–ü 3: –ü–û–î–ì–û–¢–û–í–ö–ê –î–ê–ù–ù–´–• –î–õ–Ø –ö–õ–ê–°–¢–ï–†–ò–ó–ê–¶–ò–ò")
        print("-" * 50)
        
        
        scaled_features, clean_indices = data_processor.prepare_features_for_clustering()
        
        print(f"‚úÖ –î–∞–Ω–Ω—ã–µ –æ—á–∏—â–µ–Ω—ã –æ—Ç –≤—ã–±—Ä–æ—Å–æ–≤: {len(clean_indices):,} –∫–ª–∏–µ–Ω—Ç–æ–≤")
        print(f"‚úÖ –ü—Ä–∏–∑–Ω–∞–∫–∏ –º–∞—Å—à—Ç–∞–±–∏—Ä–æ–≤–∞–Ω—ã: {scaled_features.shape[1]} –ø—Ä–∏–∑–Ω–∞–∫–æ–≤")
        
        
        feature_importance = data_processor.get_feature_importance_analysis()
        print("\nüìä –¢–æ–ø-10 –Ω–∞–∏–±–æ–ª–µ–µ –≤–∞—Ä–∏–∞—Ç–∏–≤–Ω—ã—Ö –ø—Ä–∏–∑–Ω–∞–∫–æ–≤:")
        top_features = feature_importance.nlargest(10, 'coefficient_of_variation')
        for _, row in top_features.iterrows():
            print(f"   ‚Ä¢ {row['feature']}: {row['coefficient_of_variation']:.3f}")
        
        
        data_processor.save_feature_analysis()
        
        
        
        
        print("\nü§ñ –≠–¢–ê–ü 4: –ö–õ–ê–°–¢–ï–†–ò–ó–ê–¶–ò–Ø –ö–õ–ò–ï–ù–¢–û–í")
        print("-" * 50)
        
        
        clustering_models = ClusteringModels(scaled_features, client_features.columns.tolist())
        
        
        print("\nüîç –ü–æ–∏—Å–∫ –æ–ø—Ç–∏–º–∞–ª—å–Ω–æ–≥–æ –∫–æ–ª–∏—á–µ—Å—Ç–≤–∞ –∫–ª–∞—Å—Ç–µ—Ä–æ–≤...")
        optimal_k = clustering_models.find_optimal_clusters_kmeans()
        
        
        print("\nüéØ –û–±—É—á–µ–Ω–∏–µ –º–æ–¥–µ–ª–µ–π –∫–ª–∞—Å—Ç–µ—Ä–∏–∑–∞—Ü–∏–∏...")
        
        
        clustering_models.fit_kmeans(n_clusters=optimal_k)
        
        
        clustering_models.fit_dbscan()
        
        
        clustering_models.fit_gaussian_mixture(n_components=optimal_k)
        
        
        print("\nüìä –°—Ä–∞–≤–Ω–µ–Ω–∏–µ –º–æ–¥–µ–ª–µ–π –∫–ª–∞—Å—Ç–µ—Ä–∏–∑–∞—Ü–∏–∏:")
        comparison_results = clustering_models.compare_models()
        print(comparison_results)
        
        
        best_model_name = comparison_results.loc[comparison_results['–°–∏–ª—É—ç—Ç–Ω—ã–π –∫–æ—ç—Ñ—Ñ–∏—Ü–∏–µ–Ω—Ç'].idxmax(), '–ú–æ–¥–µ–ª—å']
        
        
        model_name_mapping = {
            'Kmeans': 'kmeans',
            'Dbscan': 'dbscan', 
            'Gaussian Mixture': 'gaussian_mixture',
            'Hierarchical': 'hierarchical'
        }
        best_model_key = model_name_mapping.get(best_model_name, best_model_name.lower())
        best_labels = clustering_models.results[best_model_key]['labels']
        
        print(f"\nüèÜ –õ—É—á—à–∞—è –º–æ–¥–µ–ª—å: {best_model_name}")
        
        
        clustering_models.explain_model_choice(best_model_key)
        
        
        
        
        print("\nüìà –≠–¢–ê–ü 5: –ê–ù–ê–õ–ò–ó –°–ï–ì–ú–ï–ù–¢–û–í")
        print("-" * 50)
        
        
        segment_analyzer = SegmentAnalyzer(
            client_features=client_features,
            cluster_labels=best_labels,
            scaled_features=scaled_features,
            clean_indices=clean_indices
        )
        
        
        segment_profiles = segment_analyzer.analyze_segments()
        
        
        
        
        print("\nüé® –≠–¢–ê–ü 6: –°–û–ó–î–ê–ù–ò–ï –í–ò–ó–£–ê–õ–ò–ó–ê–¶–ò–ô")
        print("-" * 50)
        
        
        segment_analyzer.create_comprehensive_visualizations()
        
        
        
        
        print("\nüíº –≠–¢–ê–ü 7: –ì–ï–ù–ï–†–ê–¶–ò–Ø –ë–ò–ó–ù–ï–°-–†–ï–ö–û–ú–ï–ù–î–ê–¶–ò–ô")
        print("-" * 50)
        
        
        business_recommendations = segment_analyzer.generate_business_recommendations()
        
        
        
        
        print("\nüíæ –≠–¢–ê–ü 8: –°–û–•–†–ê–ù–ï–ù–ò–ï –†–ï–ó–£–õ–¨–¢–ê–¢–û–í")
        print("-" * 50)
        
        
        segment_analyzer.save_detailed_analysis()
        
        
        
        
        print("\nüìã –≠–¢–ê–ü 9: –ò–¢–û–ì–û–í–û–ï –†–ï–ó–Æ–ú–ï")
        print("-" * 50)
        
        
        segment_analyzer.print_executive_summary()
        
        
        
        
        print("\n" + "="*80)
        print("üéâ –ê–ù–ê–õ–ò–ó –£–°–ü–ï–®–ù–û –ó–ê–í–ï–†–®–ï–ù!")
        print("="*80)
        
        print(f"üìÅ –í—Å–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã —Å–æ—Ö—Ä–∞–Ω–µ–Ω—ã –≤ –ø–∞–ø–∫–µ: {config.data.output_dir}")
        print("\nüìä –°–æ–∑–¥–∞–Ω–Ω—ã–µ —Ñ–∞–π–ª—ã:")
        
        
        output_files = [
            "client_segments.csv - –†–µ–∑—É–ª—å—Ç–∞—Ç—ã —Å–µ–≥–º–µ–Ω—Ç–∞—Ü–∏–∏ –∫–ª–∏–µ–Ω—Ç–æ–≤",
            "segment_summary.csv - –°–≤–æ–¥–Ω–∞—è —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ –ø–æ —Å–µ–≥–º–µ–Ω—Ç–∞–º", 
            "segment_profiles.json - –î–µ—Ç–∞–ª—å–Ω—ã–µ –ø—Ä–æ—Ñ–∏–ª–∏ —Å–µ–≥–º–µ–Ω—Ç–æ–≤",
            "business_recommendations.json - –ë–∏–∑–Ω–µ—Å-—Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–∏",
            "feature_analysis.csv - –ê–Ω–∞–ª–∏–∑ –≤–∞–∂–Ω–æ—Å—Ç–∏ –ø—Ä–∏–∑–Ω–∞–∫–æ–≤",
            "segment_dashboard.html - –ò–Ω—Ç–µ—Ä–∞–∫—Ç–∏–≤–Ω—ã–π –¥–∞—à–±–æ—Ä–¥",
            "segment_analysis_static.png - –°—Ç–∞—Ç–∏—á–Ω—ã–µ –≥—Ä–∞—Ñ–∏–∫–∏",
            "pca_visualization.png - PCA –≤–∏–∑—É–∞–ª–∏–∑–∞—Ü–∏—è",
            "segment_heatmap.png - –¢–µ–ø–ª–æ–≤–∞—è –∫–∞—Ä—Ç–∞ —Ö–∞—Ä–∞–∫—Ç–µ—Ä–∏—Å—Ç–∏–∫",
            "cluster_optimization.png - –ì—Ä–∞—Ñ–∏–∫ –æ–ø—Ç–∏–º–∏–∑–∞—Ü–∏–∏ –∫–ª–∞—Å—Ç–µ—Ä–æ–≤"
        ]
        
        for file_desc in output_files:
            print(f"   ‚Ä¢ {file_desc}")
        
        print("\nüí° –†–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–∏ –ø–æ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—é —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤:")
        print("   1. –ò–∑—É—á–∏—Ç–µ –∏–Ω—Ç–µ—Ä–∞–∫—Ç–∏–≤–Ω—ã–π –¥–∞—à–±–æ—Ä–¥ –¥–ª—è –æ–±—â–µ–≥–æ –ø–æ–Ω–∏–º–∞–Ω–∏—è —Å–µ–≥–º–µ–Ω—Ç–æ–≤")
        print("   2. –ò—Å–ø–æ–ª—å–∑—É–π—Ç–µ –±–∏–∑–Ω–µ—Å-—Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–∏ –¥–ª—è –ø–ª–∞–Ω–∏—Ä–æ–≤–∞–Ω–∏—è –º–∞—Ä–∫–µ—Ç–∏–Ω–≥–æ–≤—ã—Ö –∫–∞–º–ø–∞–Ω–∏–π")
        print("   3. –†–µ–≥—É–ª—è—Ä–Ω–æ –æ–±–Ω–æ–≤–ª—è–π—Ç–µ —Å–µ–≥–º–µ–Ω—Ç–∞—Ü–∏—é —Å –Ω–æ–≤—ã–º–∏ –¥–∞–Ω–Ω—ã–º–∏")
        print("   4. –ú–æ–Ω–∏—Ç–æ—Ä—å—Ç–µ KPI –¥–ª—è –æ—Ü–µ–Ω–∫–∏ —ç—Ñ—Ñ–µ–∫—Ç–∏–≤–Ω–æ—Å—Ç–∏ —Å—Ç—Ä–∞—Ç–µ–≥–∏–π")
        
        print("\nüöÄ –°–ª–µ–¥—É—é—â–∏–µ —à–∞–≥–∏:")
        print("   ‚Ä¢ –í–Ω–µ–¥—Ä–µ–Ω–∏–µ –ø–µ—Ä—Å–æ–Ω–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω–Ω—ã—Ö –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏–π")
        print("   ‚Ä¢ A/B —Ç–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ —Å—Ç—Ä–∞—Ç–µ–≥–∏–π –¥–ª—è –∫–∞–∂–¥–æ–≥–æ —Å–µ–≥–º–µ–Ω—Ç–∞")
        print("   ‚Ä¢ –ê–≤—Ç–æ–º–∞—Ç–∏–∑–∞—Ü–∏—è –ø—Ä–æ—Ü–µ—Å—Å–∞ —Å–µ–≥–º–µ–Ω—Ç–∞—Ü–∏–∏")
        print("   ‚Ä¢ –ò–Ω—Ç–µ–≥—Ä–∞—Ü–∏—è —Å CRM —Å–∏—Å—Ç–µ–º–æ–π –±–∞–Ω–∫–∞")
        
        return True
        
    except Exception as e:
        print(f"\n‚ùå –û–®–ò–ë–ö–ê –ü–†–ò –í–´–ü–û–õ–ù–ï–ù–ò–ò –ê–ù–ê–õ–ò–ó–ê:")
        print(f"   {str(e)}")
        print("\nüîß –†–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–∏ –ø–æ —É—Å—Ç—Ä–∞–Ω–µ–Ω–∏—é:")
        print("   1. –ü—Ä–æ–≤–µ—Ä—å—Ç–µ –Ω–∞–ª–∏—á–∏–µ —Ñ–∞–π–ª–∞ –¥–∞–Ω–Ω—ã—Ö")
        print("   2. –£–±–µ–¥–∏—Ç–µ—Å—å –≤ –∫–æ—Ä—Ä–µ–∫—Ç–Ω–æ—Å—Ç–∏ –ø—É—Ç–µ–π")
        print("   3. –ü—Ä–æ–≤–µ—Ä—å—Ç–µ —É—Å—Ç–∞–Ω–æ–≤–∫—É –≤—Å–µ—Ö –∑–∞–≤–∏—Å–∏–º–æ—Å—Ç–µ–π")
        return False

def run_quick_analysis():
    """–ë—ã—Å—Ç—Ä—ã–π –∞–Ω–∞–ª–∏–∑ –¥–ª—è –¥–µ–º–æ–Ω—Å—Ç—Ä–∞—Ü–∏–∏"""
    print("\n‚ö° –†–ï–ñ–ò–ú –ë–´–°–¢–†–û–ì–û –ê–ù–ê–õ–ò–ó–ê")
    print("-" * 30)
    
    try:
        
        data_processor = DataProcessor(config.data.data_file)
        
        
        client_features = data_processor.create_behavioral_features()
        
        
        sample_size = min(10000, len(client_features))
        sample_features = client_features.sample(n=sample_size, random_state=42)
        
        print(f"üìä –ê–Ω–∞–ª–∏–∑–∏—Ä—É–µ–º –≤—ã–±–æ—Ä–∫—É: {sample_size:,} –∫–ª–∏–µ–Ω—Ç–æ–≤")
        
        
        scaled_features, clean_indices = data_processor.prepare_features_for_clustering()
        
        
        scaled_sample = scaled_features[:sample_size]
        clean_sample = clean_indices[:sample_size]
        
        
        clustering_models = ClusteringModels(scaled_sample, sample_features.columns.tolist())
        clustering_models.fit_kmeans(n_clusters=5)  
        
        
        segment_analyzer = SegmentAnalyzer(
            client_features=sample_features,
            cluster_labels=clustering_models.results['kmeans']['labels'],
            scaled_features=scaled_sample,
            clean_indices=clean_sample
        )
        
        
        segment_analyzer.analyze_segments()
        
        
        segment_analyzer.print_executive_summary()
        
        print("\n‚úÖ –ë—ã—Å—Ç—Ä—ã–π –∞–Ω–∞–ª–∏–∑ –∑–∞–≤–µ—Ä—à–µ–Ω!")
        
    except Exception as e:
        print(f"‚ùå –û—à–∏–±–∫–∞ –≤ –±—ã—Å—Ç—Ä–æ–º –∞–Ω–∞–ª–∏–∑–µ: {str(e)}")

if __name__ == "__main__":
    import sys
    
    
    if len(sys.argv) > 1 and sys.argv[1] == "--quick":
        run_quick_analysis()
    else:
        main() 